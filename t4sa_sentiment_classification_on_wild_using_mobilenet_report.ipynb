{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import importlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 75)\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Display progress logs on stdout\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                  format='%(asctime)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcolzutils import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/28800526...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/33547480...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/27176682...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/10096570...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/13247920...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            X  \\\n",
       "0  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/28800526...   \n",
       "1  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/33547480...   \n",
       "2  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/27176682...   \n",
       "3  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/10096570...   \n",
       "4  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/13247920...   \n",
       "\n",
       "   y  \n",
       "0  0  \n",
       "1  1  \n",
       "2  1  \n",
       "3  1  \n",
       "4  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load TTD to cross verify\n",
    "ttd_basedir=\"/home/tutysara/src/myprojects/senti/dataset\"\n",
    "ttd_data_idx_path = ttd_basedir+ \"/twitter_five_agrees.txt\"\n",
    "col_names = [\"X\", \"y\"]\n",
    "ttd_data_df = pd.read_csv(ttd_data_idx_path, sep=\" \", header=None, names=col_names)\n",
    "ttd_data_df.X = ttd_data_df.X.apply(lambda x: ttd_basedir+\"/Agg_AMT_Candidates/\"+x)\n",
    "print(ttd_data_df.shape)\n",
    "ttd_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir=\"/media/hdd/datastore/t4sa\"\n",
    "\n",
    "valid_name = basedir + '/valid_data'\n",
    "test_name = basedir + '/test_data'\n",
    "train_name = basedir +'/train_data' \n",
    "\n",
    "bnf_valid_name = basedir +'/bottleneck_features_mobilenet_valid'\n",
    "bnf_test_name = basedir +'/bottleneck_features_mobilenet_test' \n",
    "bnf_train_name = basedir +'/bottleneck_features_mobilenet_train'\n",
    "\n",
    "test_prefix = \"\"\n",
    "top_model_test_result = 'bottleneck_features_mobilenet_result.npz'\n",
    "full_model_test_result = f'finetune_fullmodel_mobilenet_result{test_prefix}.npz'\n",
    "top_model_weight_path = f'saved_models/weights.best.topmodel.mobilenet.hdf5'\n",
    "full_model_weight_path = f'saved_models/weights.best.fullmodel.mobilenet{test_prefix}.hdf5'\n",
    "\n",
    "top_model_loss_history = 'finetune_fullmodel_mobilenet_loss_history.csv'\n",
    "finetune_model_loss_history = 'finetune_fullmodel_mobilenet_loss_history.csv'\n",
    "\n",
    "num_classes = 3\n",
    "percent = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data in bcolz format\n",
      "(51000, 224, 224, 3)\n",
      "(51000, 224, 224, 3)\n",
      "(368586, 224, 224, 3)\n",
      "(51000, 3)\n",
      "(51000, 3)\n",
      "(368586, 3)\n"
     ]
    }
   ],
   "source": [
    "# read from disk and check size\n",
    "valid_data = bcolz.carray(rootdir= valid_name+'_data.bclz', mode='r')\n",
    "test_data = bcolz.carray(rootdir= test_name + '_data.bclz', mode='r')\n",
    "train_data = bcolz.carray(rootdir= train_name+ '_data.bclz', mode='r')\n",
    "\n",
    "\n",
    "valid_labels = bcolz.carray(rootdir= valid_name+'_labels.bclz', mode='r')\n",
    "test_labels = bcolz.carray(rootdir= test_name + '_labels.bclz', mode='r')\n",
    "train_labels = bcolz.carray(rootdir= train_name+ '_labels.bclz', mode='r')\n",
    "\n",
    "print(\"Raw data in bcolz format\")\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.shape)\n",
    "\n",
    "print(valid_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to bottleneck features using \n",
    "#%ipython tx2_bottleneck_mobilenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottle Neck Features data in bcolz format\n",
      "(51000, 7, 7, 1024)\n",
      "(51000, 7, 7, 1024)\n",
      "(368586, 7, 7, 1024)\n",
      "(51000, 3)\n",
      "(51000, 3)\n",
      "(368586, 3)\n"
     ]
    }
   ],
   "source": [
    "## Read it back from disk and check size\n",
    "bnf_valid_data = bcolz.carray(rootdir=f'{bnf_valid_name}_data.bclz', mode='r')\n",
    "bnf_test_data = bcolz.carray(rootdir=f'{bnf_test_name}_data.bclz', mode='r')\n",
    "bnf_train_data = bcolz.carray(rootdir=f'{bnf_train_name}_data.bclz', mode='r')\n",
    "\n",
    "bnf_valid_labels = bcolz.carray(rootdir=f'{bnf_valid_name}_labels.bclz', mode='r')\n",
    "bnf_test_labels = bcolz.carray(rootdir=f'{bnf_test_name}_labels.bclz', mode='r')\n",
    "bnf_train_labels = bcolz.carray(rootdir=f'{bnf_train_name}_labels.bclz', mode='r')\n",
    "\n",
    "\n",
    "print(\"Bottle Neck Features data in bcolz format\")\n",
    "print(bnf_valid_data.shape)\n",
    "print(bnf_test_data.shape)\n",
    "print(bnf_train_data.shape)\n",
    "\n",
    "\n",
    "print(bnf_valid_labels.shape)\n",
    "print(bnf_test_labels.shape)\n",
    "print(bnf_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a generator of loaded bottleneck features\n",
    "batch_size = 256\n",
    "bnf_train_gen =bcolz_data_generator(bnf_train_data, bnf_train_labels, batch_size=batch_size)\n",
    "bnf_valid_gen =bcolz_data_generator(bnf_valid_data, bnf_valid_labels, batch_size=batch_size)\n",
    "bnf_test_gen =bcolz_data_generator(bnf_test_data, bnf_test_labels, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 3)           3075      \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 3)           0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,075\n",
      "Trainable params: 3,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Reshape\n",
    "from keras import regularizers\n",
    "\n",
    "alpha = 1\n",
    "dropout=1e-3\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape = (int(1024 * alpha), 1, 1)\n",
    "else:\n",
    "    shape = (1, 1, int(1024 * alpha))\n",
    "\n",
    "classes = num_classes\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=(7, 7, 1024)))\n",
    "top_model.add(Reshape(shape, name='reshape_1'))\n",
    "top_model.add(Dropout(dropout, name='dropout'))\n",
    "top_model.add(Conv2D(classes, (1, 1),\n",
    "           padding='same', name='conv_preds'))\n",
    "top_model.add(Activation('softmax', name='act_softmax'))\n",
    "top_model.add(Reshape((classes,), name='reshape_2'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.topmodel.mobilenet_test.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "top_model.fit_generator(bnf_train_gen,\n",
    "          steps_per_epoch= int(1 + (bnf_train_data.shape[0] * percent // batch_size)),\n",
    "          epochs=15,\n",
    "          validation_data=bnf_valid_gen,\n",
    "          validation_steps= (1 + (bnf_valid_data.shape[0] * percent // batch_size)),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using\n",
    "# ipython tx2_bottleneck_mobilenet.py\n",
    "#\n",
    "#syrupy.py --separator=, --no-align --no-raw-process-log  ipython train_top_model_with_bottleneck_features_mobilenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.load_weights(top_model_weight_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_true, y_pred = prediction_from_gen(gen=bnf_test_gen,\n",
    "                                     steps=int(1 + (bnf_test_data.shape[0] * percent // batch_size)),\n",
    "                                     model=top_model,\n",
    "                                     dirname=\"bottleneck_features_mobilenet_test\")\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# write to disk\n",
    "test_result = 'bottleneck_features_mobilenet_result.npz'\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "print(type(y_true), type(y_pred))\n",
    "np.savez(test_result, y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 3)\n",
      "(51000, 3)\n"
     ]
    }
   ],
   "source": [
    "# read back and check\n",
    "npzfile = np.load(top_model_test_result)\n",
    "y_true = npzfile['y_true']\n",
    "y_pred = npzfile['y_pred']\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.4176%\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.argmax(y_pred, axis=1)==np.argmax(y_true, axis=1))/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report test accuracy on TTD\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobilenet_preprocess_input\n",
    "mobilenet_feature_ext = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "mobilenet_feature_ext._make_predict_function()\n",
    "\n",
    "ttd_X1 = ttd_data_df.X.as_matrix()\n",
    "ttd_X2 = mobilenet_preprocess_input(paths_to_tensor(ttd_X1))\n",
    "ttd_X = mobilenet_feature_ext.predict(ttd_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttd_y_pred = top_model.predict(ttd_X)\n",
    "ttd_y_pred_two_classes=ttd_y_pred[:,[0,2]]\n",
    "ttd_y_true = ttd_data_df.y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882, 7, 7, 1024)\n",
      "(882, 3)\n",
      "(882,)\n"
     ]
    }
   ],
   "source": [
    "print(ttd_X.shape)\n",
    "print(ttd_y_pred.shape)\n",
    "print(ttd_y_true.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTD Test accuracy: 71.6553%\n"
     ]
    }
   ],
   "source": [
    "ttd_test_accuracy = 100*np.sum(np.argmax(ttd_y_pred_two_classes, axis=1)==ttd_y_true)/len(ttd_y_true)\n",
    "print('TTD Test accuracy: %.4f%%' % ttd_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.464423</td>\n",
       "      <td>1.035530</td>\n",
       "      <td>0.465784</td>\n",
       "      <td>1.038422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464361</td>\n",
       "      <td>1.035470</td>\n",
       "      <td>0.465784</td>\n",
       "      <td>1.038422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464486</td>\n",
       "      <td>1.035522</td>\n",
       "      <td>0.465784</td>\n",
       "      <td>1.038422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       acc      loss   val_acc  val_loss\n",
       "0      0  0.464423  1.035530  0.465784  1.038422\n",
       "1      1  0.464361  1.035470  0.465784  1.038422\n",
       "2      2  0.464486  1.035522  0.465784  1.038422"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model_loss_history_df = pd.read_csv(top_model_loss_history)\n",
    "top_model_loss_history_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3b75c8588>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGklJREFUeJzt3X10VfWd7/H3V4hEBkQiEZQwAvdigxDwIbKsDqAyVmAq\nqTo0UB8Kt+LVKtTa65KCbR1Ka59WHV2XK8N1UcGxAqLMoiPKrQWljqIcuDzIgwyNDyQ+hQepjEUk\nfOePs2GOMeScJPuck/zyea2V5dl7//b+fc/O9pPN3vv8jrk7IiISlpPyXYCIiMRP4S4iEiCFu4hI\ngBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiASoY7467tGjh/ft2zdf3YuItEnr16/f4+7F\n6drlLdz79u1LIpHIV/ciIm2Smb2dSTtdlhERCZDCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQAp3\nEZEA5e059+Z6/6c/5dPtO/JdhohIs3UaWEqvGTOy2kebC3f+/B58lNEz/G2E5bsAkXYqj98ffbAo\n6120uXDvdfUAOOWfs99RTr44XF9OLpJfeTq5+rubst5Fmwt3Lp2W/JHWJRd/DHPyBxeSf3Tz+C8q\ny1Pf+epXsqLthbu0TrkIBoWPSMb0tIyISIAU7iIiAVK4i4gESOEuIhIghbuISIAU7iIiAUob7mY2\n38w+NLPXT7DczOwhM9tlZpvN7IL4yxQRkabI5Mz9UWB0I8vHAAOin1uAh1teloiItETacHf3NcC+\nRppUAAs9aS1wmpmdGVeBIiLSdHFcc+8N7E6Zro7mfYGZ3WJmCTNL1NbWxtC1iIg0JKc3VN19nruX\nu3t5cXFxLrsWEWlX4gj3GqBPynRJNE9ERPIkjnBfDtwUPTVzMXDA3d+LYbsiItJMaUeFNLMngMuA\nHmZWDfwIKABw97nACmAssAv4BJicrWJFRCQzacPd3SemWe7A7bFVJCIiLaZPqIqIBEjhLiISIIW7\niEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjh\nLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFS\nuIuIBCijcDez0Wb2hpntMrPpDSw/28z+YGabzewFMyuJv1QREclU2nA3sw7AHGAMcC4w0czOrdfs\nV8BCdx8CzALuj7tQERHJXCZn7sOAXe5e5e6HgUVARb025wKroterG1guIiI5lEm49wZ2p0xXR/NS\nbQKujV5fA3Q1s9NbXp6IiDRHXDdU/xcw0sz+PzASqAHq6jcys1vMLGFmidra2pi6FhGR+jIJ9xqg\nT8p0STTvOHd/192vdffzgZnRvI/qb8jd57l7ubuXFxcXt6BsERFpTCbhvg4YYGb9zOxkYAKwPLWB\nmfUws2Pb+j4wP94yRUSkKdKGu7sfAe4AVgLbgSXuvtXMZpnZuKjZZcAbZrYT6An8JEv1iohIBszd\n89JxeXm5JxKJvPQtItJWmdl6dy9P106fUBURCZDCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQAp3\nEZEAKdxFRAKkcBcRCZDCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQB3zXYCItC+fffYZ1dXVHDp0\nKN+ltGqFhYWUlJRQUFDQrPUV7iKSU9XV1XTt2pW+fftiZvkup1Vyd/bu3Ut1dTX9+vVr1jZ0WUZE\ncurQoUOcfvrpCvZGmBmnn356i/51o3AXkZxTsKfX0n2kcBcRCZDCXUQkQAp3EWl3vva1r3HhhRcy\naNAg5s2bB8Bzzz3HBRdcwNChQxk1ahQABw8eZPLkyZSVlTFkyBCeeuqpfJbdJHpaRkTy5h9+t5Vt\n7/451m2ee9ap/OjqQY22mT9/PkVFRfzlL3/hoosuoqKigilTprBmzRr69evHvn37APjxj39Mt27d\n2LJlCwD79++PtdZsUriLSLvz0EMPsWzZMgB2797NvHnzGDFixPHHDouKigB4/vnnWbRo0fH1unfv\nnvtim0nhLiJ5k+4MOxteeOEFnn/+eV555RU6d+7MZZddxnnnnceOHTtyXks26Zq7iLQrBw4coHv3\n7nTu3JkdO3awdu1aDh06xJo1a3jzzTcBjl+WufLKK5kzZ87xddvSZRmFu4i0K6NHj+bIkSMMHDiQ\n6dOnc/HFF1NcXMy8efO49tprGTp0KJWVlQDce++97N+/n8GDBzN06FBWr16d5+ozl9FlGTMbDTwI\ndAAecfef1Vv+18AC4LSozXR3XxFzrSIiLdapUyeeffbZBpeNGTPmc9NdunRhwYIFuSgrdmnP3M2s\nAzAHGAOcC0w0s3PrNbsXWOLu5wMTgP8Td6EiIpK5TC7LDAN2uXuVux8GFgEV9do4cGr0uhvwbnwl\niohIU2US7r2B3SnT1dG8VPcBN5hZNbACmNrQhszsFjNLmFmitra2GeWKiEgm4rqhOhF41N1LgLHA\nY2b2hW27+zx3L3f38uLi4pi6FhGR+jIJ9xqgT8p0STQv1beAJQDu/gpQCPSIo0AREWm6TMJ9HTDA\nzPqZ2ckkb5gur9fmHWAUgJkNJBnuuu4iIpInacPd3Y8AdwArge0kn4rZamazzGxc1Ox7wBQz2wQ8\nAUxyd89W0SIiLdGlS5d8l5B1GT3nHj2zvqLevB+mvN4GXBpvaSIi0lz6hKqItFvuzt13383gwYMp\nKytj8eLFALz33nuMGDGC8847j8GDB/PHP/6Ruro6Jk2adLztAw88kOfqG6eBw0Qkf56dDu9viXeb\nvcpgzM/StwOefvppNm7cyKZNm9izZw8XXXQRI0aM4Le//S1XXXUVM2fOpK6ujk8++YSNGzdSU1PD\n66+/DsBHH30Ub90x05m7iLRbL730EhMnTqRDhw707NmTkSNHsm7dOi666CJ+85vfcN9997Flyxa6\ndu1K//79qaqqYurUqTz33HOceuqp6TvII525i0j+ZHiGnWsjRoxgzZo1PPPMM0yaNIm77rqLm266\niU2bNrFy5Urmzp3LkiVLmD9/fr5LPSGduYtIuzV8+HAWL15MXV0dtbW1rFmzhmHDhvH222/Ts2dP\npkyZws0338yGDRvYs2cPR48e5brrrmP27Nls2LAh3+U3SmfuItJuXXPNNbzyyisMHToUM+MXv/gF\nvXr1YsGCBfzyl7+koKCALl26sHDhQmpqapg8eTJHjx4F4P77789z9Y2zfD2OXl5e7olEIi99i0j+\nbN++nYEDB+a7jDahoX1lZuvdvTzdurosIyISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4i\nIgFSuIuINKKtjv2ucBcRCZCGHxCRvPn5az9nx74dsW6ztKiUe4bdc8Ll06dPp0+fPtx+++0A3Hff\nfXTs2JHVq1ezf/9+PvvsM2bPnk1FRUXavg4ePEhFRUWD6y1cuJBf/epXmBlDhgzhscce44MPPuDW\nW2+lqqoKgIcffphLLrkkhnf9RQp3EWlXKisrufPOO4+H+5IlS1i5ciXTpk3j1FNPZc+ePVx88cWM\nGzcOM2t0W4WFhSxbtuwL623bto3Zs2fz8ssv06NHD/bt2wfAtGnTGDlyJMuWLaOuro6DBw9m7X0q\n3EUkbxo7w86W888/nw8//JB3332X2tpaunfvTq9evfjud7/LmjVrOOmkk6ipqeGDDz6gV69ejW7L\n3ZkxY8YX1lu1ahXjx4+nR48eABQVFQGwatUqFi5cCECHDh3o1q1b1t6nwl1E2p3x48ezdOlS3n//\nfSorK3n88cepra1l/fr1FBQU0LdvXw4dOpR2O81dLxd0Q1VE2p3KykoWLVrE0qVLGT9+PAcOHOCM\nM86goKCA1atX8/bbb2e0nROtd8UVV/Dkk0+yd+9egOOXZUaNGsXDDz8MQF1dHQcOHMjCu0tSuItI\nuzNo0CA+/vhjevfuzZlnnsn1119PIpGgrKyMhQsXUlpamtF2TrTeoEGDmDlzJiNHjmTo0KHcdddd\nADz44IOsXr2asrIyLrzwQrZt25a196jx3EUkpzSee+Y0nruIiHyObqiKiKSxZcsWbrzxxs/N69Sp\nE6+++mqeKkovo3A3s9HAg0AH4BF3/1m95Q8Al0eTnYEz3P20OAsVEcmXsrIyNm7cmO8ymiRtuJtZ\nB2AOcCVQDawzs+XufvxOgLt/N6X9VOD8LNQqIiIZyuSa+zBgl7tXufthYBHQ2OdyJwJPxFGciIg0\nTybh3hvYnTJdHc37AjM7G+gHrGp5aSIi0lxxPy0zAVjq7nUNLTSzW8wsYWaJ2tramLsWEZFjMgn3\nGqBPynRJNK8hE2jkkoy7z3P3cncvLy4uzrxKEZE8aWw897feeovBgwfnsJrMZRLu64ABZtbPzE4m\nGeDL6zcys1KgO/BKvCWKiEhTpX1axt2PmNkdwEqSj0LOd/etZjYLSLj7saCfACzyfH3kVUTanPd/\n+lM+3R7veO6dBpbSa8aMEy6Pczz3VIcOHeK2224jkUjQsWNHfv3rX3P55ZezdetWJk+ezOHDhzl6\n9ChPPfUUZ511Fl//+teprq6mrq6OH/zgB1RWVrbofdeX0XPu7r4CWFFv3g/rTd8XX1kiItkR53ju\nqebMmYOZsWXLFnbs2MFXvvIVdu7cydy5c/nOd77D9ddfz+HDh6mrq2PFihWcddZZPPPMMwBZGUBM\nn1AVkbxp7Aw7W+Iczz3VSy+9xNSpUwEoLS3l7LPPZufOnXz5y1/mJz/5CdXV1Vx77bUMGDCAsrIy\nvve973HPPffw1a9+leHDh8f+PjW2jIi0O8fGc1+8ePEXxnPfuHEjPXv2jG1c9m984xssX76cU045\nhbFjx7Jq1SrOOeccNmzYQFlZGffeey+zZs2Kpa9UOnMXkXansrKSKVOmsGfPHl588UWWLFnSrPHc\nUw0fPpzHH3+cK664gp07d/LOO+/wpS99iaqqKvr378+0adN455132Lx5M6WlpRQVFXHDDTdw2mmn\n8cgjj8T+HhXuItLuNDSe+9VXX01ZWRnl5eUZj+ee6tvf/ja33XYbZWVldOzYkUcffZROnTqxZMkS\nHnvsMQoKCujVqxczZsxg3bp13H333Zx00kkUFBQc/wKPOGk8dxHJKY3nnjmN5y4iIp+jyzIiImkE\nO567iEic3L1Jz5DnWz7Gc2/pJXNdlhGRnCosLGTv3r0tDq+QuTt79+6lsLCw2dvQmbuI5FRJSQnV\n1dVoZNjGFRYWUlJS0uz1Fe4iklMFBQX069cv32UET5dlREQCpHAXEQmQwl1EJEAKdxGRACncRUQC\npHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAZhbuZ\njTazN8xsl5lNP0Gbr5vZNjPbama/jbdMERFpirRf1mFmHYA5wJVANbDOzJa7+7aUNgOA7wOXuvt+\nMzsjWwWLiEh6mZy5DwN2uXuVux8GFgEV9dpMAea4+34Ad/8w3jJFRKQpMgn33sDulOnqaF6qc4Bz\nzOzfzGytmY1uaENmdouZJcwsoe9PFBHJnrhuqHYEBgCXAROB/2tmp9Vv5O7z3L3c3cuLi4tj6lpE\nROrLJNxrgD4p0yXRvFTVwHJ3/8zd3wR2kgx7ERHJg0zCfR0wwMz6mdnJwARgeb02/0LyrB0z60Hy\nMk1VjHWKiEgTpA13dz8C3AGsBLYDS9x9q5nNMrNxUbOVwF4z2wasBu52973ZKlpERBpn7p6XjsvL\nyz2RSOSlbxGRtsrM1rt7ebp2+oSqiEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjh\nLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFS\nuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAMgp3MxttZm+Y2S4zm97A8klmVmtm\nG6Ofm+MvVUREMtUxXQMz6wDMAa4EqoF1Zrbc3bfVa7rY3e/IQo0iItJEmZy5DwN2uXuVux8GFgEV\n2S1LRERaIpNw7w3sTpmujubVd52ZbTazpWbWJ5bqRESkWeK6ofo7oK+7DwF+DyxoqJGZ3WJmCTNL\n1NbWxtS1iIjUl0m41wCpZ+Il0bzj3H2vu38aTT4CXNjQhtx9nruXu3t5cXFxc+oVEZEMZBLu64AB\nZtbPzE4GJgDLUxuY2Zkpk+OA7fGVKCIiTZX2aRl3P2JmdwArgQ7AfHffamazgIS7Lwemmdk44Aiw\nD5iUxZpFRCQNc/e8dFxeXu6JRCIvfYuItFVmtt7dy9O10ydURUQCpHAXEQmQwl1EJEAKdxGRACnc\nRUQClPZRyNbm56/9nB37duS7DBGRZistKuWeYfdktY82F+5vvP8xGz/4KN9lxMaC60hypplPMefn\n4efcyPl7a2aHBXUH462jAW0u3K8fMJWun7yb9X5y8fh/rg7EXHyWISfvJUc7zHGsuX8Nc7saZs1b\nszlrNbOrNvHeWrJic46V60obGnsxXm0u3EcN7MmogT3zXYaISKumG6oiIgFSuIuIBEjhLiISIIW7\niEiAFO4iIgFSuIuIBEjhLiISIIW7iEiA8vZNTGZWC7zdzNV7AHtiLCcuqqtpVFfTtdbaVFfTtKSu\ns929OF2jvIV7S5hZIpOvmco11dU0qqvpWmttqqtpclGXLsuIiARI4S4iEqC2Gu7z8l3ACaiuplFd\nTddaa1NdTZP1utrkNXcREWlcWz1zFxGRRrS6cDez0Wb2hpntMrPpDSzvZGaLo+WvmlnflGXfj+a/\nYWZX5biuu8xsm5ltNrM/mNnZKcvqzGxj9LM8x3VNMrPalP5vTln2TTP79+jnmzmu64GUmnaa2Ucp\ny7K5v+ab2Ydm9voJlpuZPRTVvdnMLkhZlpX9lUFN10e1bDGzl81saMqyt6L5G80sEVdNTajtMjM7\nkPL7+mHKskaPgSzXdXdKTa9Hx1RRtCwr+8zM+pjZ6igHtprZdxpok7vjy91bzQ/QAfgT0B84GdgE\nnFuvzbeBudHrCcDi6PW5UftOQL9oOx1yWNflQOfo9W3H6oqmD+Zxf00C/ncD6xYBVdF/u0evu+eq\nrnrtpwLzs72/om2PAC4AXj/B8rHAsyS/l+di4NUc7K90NV1yrC9gzLGaoum3gB553F+XAf/a0mMg\n7rrqtb0aWJXtfQacCVwQve4K7Gzg/8ecHV+t7cx9GLDL3avc/TCwCKio16YCWBC9XgqMMjOL5i9y\n90/d/U1gV7S9nNTl7qvd/ZNoci1QElPfLaqrEVcBv3f3fe6+H/g9MDpPdU0Enoip70a5+xpgXyNN\nKoCFnrQWOM3MziSL+ytdTe7+ctQn5O7YOtZ3uv11Ii05NuOuKyfHl7u/5+4botcfA9uB+t+nl7Pj\nq7WFe29gd8p0NV/cOcfbuPsR4ABweobrZrOuVN8i+df5mEIzS5jZWjP7Wkw1NaWu66J/Ai41sz5N\nXDebdRFdvuoHrEqZna39lYkT1Z7N/dUU9Y8tB/6fma03s1vyUA/Al81sk5k9a2aDonmtYn+ZWWeS\nIflUyuys7zNLXi4+H3i13qKcHV9t7jtUWzszuwEoB0amzD7b3WvMrD+wysy2uPufclTS74An3P1T\nM/ufJP/Vc0WO+s7EBGCpu9elzMvn/mq1zOxykuH+Nymz/ybaV2cAvzezHdFZba5sIPn7OmhmY4F/\nAQbksP90rgb+zd1Tz/Kzus/MrAvJPyZ3uvuf49puU7W2M/caoE/KdEk0r8E2ZtYR6AbszXDdbNaF\nmf0tMBMY5+6fHpvv7jXRf6uAF0j+Rc9JXe6+N6WWR4ALM103m3WlmEC9fzJncX9l4kS1Z3N/pWVm\nQ0j+/ircfe+x+Sn76kNgGfFdisyIu//Z3Q9Gr1cABWbWgzzvrxSNHV+x7zMzKyAZ7I+7+9MNNMnd\n8RX3TYUW3pDoSPJGQj/+6ybMoHptbufzN1SXRK8H8fkbqlXEd0M1k7rOJ3kDaUC9+d2BTtHrHsC/\nE9ONpQzrOjPl9TXAWv+vGzhvRvV1j14X5aquqF0pyZtblov9ldJHX058g/Dv+PwNr9eyvb8yqOmv\nSd5DuqTe/L8Cuqa8fhkYHee+yqC2Xsd+fyRD8p1o32V0DGSrrmh5N5LX5f8qF/sset8LgX9spE3O\njq9YD4KYdtBYkneZ/wTMjObNInk2DFAIPBkd7K8B/VPWnRmt9wYwJsd1PQ98AGyMfpZH8y8BtkQH\n9xbgWzmu635ga9T/aqA0Zd3/Ee3HXcDkXNYVTd8H/KzeetneX08A7wGfkbyu+S3gVuDWaLkBc6K6\ntwDl2d5fGdT0CLA/5dhKRPP7R/tpU/Q7nhnnvsqwtjtSjq+1pPwBaugYyFVdUZtJJB+ySF0va/uM\n5OUyBzan/K7G5uv40idURUQC1NquuYuISAwU7iIiAVK4i4gESOEuIhIghbuISIAU7iLNEI2G+K/5\nrkPkRBTuIiIBUrhL0MzsBjN7LRq7+5/MrIOZHYzGk99qybH3i6O250WDlW02s2Vm1j2a/9/N7Plo\ncKwNZvbfos13iQZj22Fmj0ejk4q0Cgp3CZaZDQQqgUvd/TygDrie5MfOE+4+CHgR+FG0ykLgHncf\nQvLTg8fmPw7McfehJD9B+140/3zgTpLfJdAfuDTrb0okQxoVUkI2iuRAaeuik+pTgA+Bo8DiqM0/\nA0+bWTfgNHd/MZq/AHjSzLoCvd19GYC7HwKItveau1dH0xtJjnXyUvbflkh6CncJmQEL3P37n5tp\n9oN67Zo7BsenKa/r0P9P0orosoyE7A/A30fjdmNmRdGXg5wE/H3U5hvAS+5+ANhvZsOj+TcCL3ry\nG3Wqj31piCW/w7dzTt+FSDPoTEOC5e7bzOxekt+6cxLJEQRvB/4DGBYt+5DkdXmAbwJzo/CuAiZH\n828E/snMZkXbGJ/DtyHSLBoVUtodMzvo7l3yXYdINumyjIhIgHTmLiISIJ25i4gESOEuIhIghbuI\nSIAU7iIiAVK4i4gESOEuIhKg/wTKe5F6ojkYjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3af67f3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_model_loss_history_df.plot(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,231,939\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine tune on full model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "mobilenet_model = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# CREATE AN \"REAL\" MODEL FROM Mobilenet\n",
    "# BY COPYING ALL THE LAYERS OF Mobilenet\n",
    "model = Sequential()\n",
    "for l in mobilenet_model.layers:\n",
    "    model.add(l)\n",
    "\n",
    "\n",
    "# CONCATENATE THE TWO MODELS\n",
    "model.add(top_model)\n",
    "\n",
    "# LOCK THE TOP CONV LAYERS\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# COMPILE THE MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load train, test, and validation datasets\n",
    "batch_size = 256\n",
    "valid_data_gen = bcolz_data_generator(valid_data, valid_labels, batch_size=batch_size, progress=False)\n",
    "test_data_gen = bcolz_data_generator(test_data, test_labels, batch_size=batch_size, progress=False)\n",
    "train_data_gen = bcolz_data_generator(train_data, train_labels, batch_size=batch_size, progress=False)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.fullmodel.mobilenet_test.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "model.fit_generator(train_data_gen,\n",
    "          steps_per_epoch= int(1+ train_data.shape[0] * percent// batch_size),\n",
    "          epochs=2,\n",
    "          validation_data=valid_data_gen,\n",
    "          validation_steps= int(1+ valid_data.shape[0] * percent // batch_size),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(full_model_weight_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valid_data_gen = bcolz_data_generator(valid_data, valid_labels, batch_size=batch_size, progress=False)\n",
    "test_data_gen = bcolz_data_generator(test_data, test_labels, batch_size=batch_size, progress=False)\n",
    "train_data_gen = bcolz_data_generator(train_data, train_labels, batch_size=batch_size, progress=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_true, y_pred = prediction_from_gen(gen=test_data_gen,\n",
    "                                     steps=(1 + int(test_data.shape[0]*percent // batch_size)),\n",
    "                                     model=model,\n",
    "                                     dirname=test_name)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full mode result\n",
    "npzfile = np.load(full_model_test_result)\n",
    "y_true = npzfile['y_true']\n",
    "y_pred = npzfile['y_pred']\n",
    "log.debug(y_true.shape)\n",
    "log.debug(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 46.3922%\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.argmax(y_pred, axis=1)==np.argmax(y_true, axis=1))/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report test accuracy on TTD\n",
    "ttd_X1 = ttd_data_df.X.as_matrix()\n",
    "ttd_y_pred = model.predict(paths_to_tensor(ttd_X1))\n",
    "    \n",
    "ttd_y_pred_two_classes=ttd_y_pred[:,[0,2]]\n",
    "ttd_y_true = ttd_data_df.y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTD Test accuracy: 73.2426%\n"
     ]
    }
   ],
   "source": [
    "ttd_test_accuracy = 100*np.sum(np.argmax(ttd_y_pred_two_classes, axis=1)==ttd_y_true)/len(ttd_y_true)\n",
    "print('TTD Test accuracy: %.4f%%' % ttd_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
