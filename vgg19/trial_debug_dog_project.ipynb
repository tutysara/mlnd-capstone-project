{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bcolz\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from bcolzutils import *\n",
    "from util import *\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:fine tune all layers\n",
      "DEBUG:__main__:using all_model_weight_path :saved_models/test_all_layers_caffe_vgg19_weights.hdf5\n",
      "DEBUG:__main__:using test_result :saved_models/test_all_layers_caffe_vgg19_result.npz\n",
      "DEBUG:__main__:using loss_history_csv_name :test_all_layers.caffe_vgg19_loss_history.csv\n"
     ]
    }
   ],
   "source": [
    "arch = \"caffe_vgg19\"\n",
    "basedir=\"/media/hdd/datastore/t4sa\"\n",
    "#basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "\n",
    "percent = 0.005\n",
    "#percent = 1\n",
    "epochs=5\n",
    "#epochs=15\n",
    "#num_classes = 133\n",
    "num_classes = 3 \n",
    "#batch_size = 48\n",
    "batch_size = 64\n",
    "lr=1e-3\n",
    "momentum=0.9\n",
    "l2_weight_decay = 1e-5\n",
    "test_prefix=\"\"\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" divides the lr by 10 every 5 epochs\"\"\"\n",
    "    n = (epoch + 1) // 5\n",
    "    return lr / (10 ** n)\n",
    "\n",
    "if percent < 1:\n",
    "    test_prefix = \"test_\"\n",
    "\n",
    "d = datetime.datetime.today()\n",
    "\n",
    "model_path = f'saved_models/{test_prefix}all_layers_{arch}_weights.hdf5'\n",
    "loss_history_csv_name = f'{test_prefix}all_layers.{arch}_loss_history.csv'\n",
    "test_result = f'saved_models/{test_prefix}all_layers_{arch}_result.npz'\n",
    "log_filename=f\"all_layer_train_{arch}_{d.year}-{d.month}-{d.day}-{d.hour}.{d.minute}.{d.second}_{test_prefix}.log\"\n",
    "\n",
    "\n",
    "logging.basicConfig(level='DEBUG',\n",
    "                    handlers=[logging.FileHandler(log_filename),\n",
    "                              logging.StreamHandler()])\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "log.debug(\"fine tune all layers\")\n",
    "log.debug(\"using all_model_weight_path :\" + model_path)\n",
    "log.debug(\"using test_result :\" + test_result)\n",
    "log.debug(\"using loss_history_csv_name :\" + loss_history_csv_name)\n",
    "\n",
    "train_name = basedir + '/pp_train_data'\n",
    "valid_name = basedir + '/pp_valid_data'\n",
    "test_name = basedir + '/pp_test_data'\n",
    "\n",
    "temp_dir = \"/tmp/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 66038528\n",
      "drwxrwxrwx 1 root root           0 Feb 12 21:36 \u001b[0m\u001b[34;42mbottleneck_features_mobilenet_test_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 12 21:36 \u001b[34;42mbottleneck_features_mobilenet_test_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 21 20:50 \u001b[34;42mbottleneck_features_mobilenet_test_y_pred.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 21 20:50 \u001b[34;42mbottleneck_features_mobilenet_test_y_true.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 12 21:49 \u001b[34;42mbottleneck_features_mobilenet_train_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 12 21:49 \u001b[34;42mbottleneck_features_mobilenet_train_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 12 21:23 \u001b[34;42mbottleneck_features_mobilenet_valid_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 12 21:23 \u001b[34;42mbottleneck_features_mobilenet_valid_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 23 23:50 \u001b[34;42mbottleneck_features_vgg19_test_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 23 23:50 \u001b[34;42mbottleneck_features_vgg19_test_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  4 15:31 \u001b[34;42mbottleneck_features_vgg19_test_y_pred.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  4 15:31 \u001b[34;42mbottleneck_features_vgg19_test_y_true.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 24 00:03 \u001b[34;42mbottleneck_features_vgg19_train_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 24 00:03 \u001b[34;42mbottleneck_features_vgg19_train_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 23 23:34 \u001b[34;42mbottleneck_features_vgg19_valid_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 23 23:34 \u001b[34;42mbottleneck_features_vgg19_valid_labels.bclz\u001b[0m/\n",
      "-rwxrwxrwx 1 root root    17882268 Nov  1 14:44 \u001b[01;32mb-t4sa_all.txt\u001b[0m*\n",
      "-rwxrwxrwx 1 root root 67587461120 Dec 26 23:28 \u001b[01;32mb-t4sa_imgs.tar\u001b[0m*\n",
      "-rwxrwxrwx 1 root root     1938000 Nov  1 14:44 \u001b[01;32mb-t4sa_test.txt\u001b[0m*\n",
      "-rwxrwxrwx 1 root root    14006268 Nov  1 14:44 \u001b[01;32mb-t4sa_train.txt\u001b[0m*\n",
      "-rwxrwxrwx 1 root root     1938000 Nov  1 14:44 \u001b[01;32mb-t4sa_val.txt\u001b[0m*\n",
      "drwxrwxrwx 1 root root      217088 Dec 27 09:01 \u001b[34;42mdata\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  6 22:55 \u001b[34;42mpp_test_data_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  6 22:55 \u001b[34;42mpp_test_data_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  6 23:12 \u001b[34;42mpp_train_data_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  6 23:12 \u001b[34;42mpp_train_data_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  6 22:37 \u001b[34;42mpp_valid_data_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Mar  6 22:37 \u001b[34;42mpp_valid_data_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Dec 30 09:27 \u001b[34;42mtest_data_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Dec 30 09:27 \u001b[34;42mtest_data_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 25 20:28 \u001b[34;42mtest_data_y_pred.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Feb 25 20:28 \u001b[34;42mtest_data_y_true.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Dec 30 10:09 \u001b[34;42mtrain_data_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Dec 30 10:09 \u001b[34;42mtrain_data_labels.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Dec 30 08:43 \u001b[34;42mvalid_data_data.bclz\u001b[0m/\n",
      "drwxrwxrwx 1 root root           0 Dec 30 08:43 \u001b[34;42mvalid_data_labels.bclz\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls -l {basedir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 224, 224, 3) (51000, 3) <class 'bcolz.carray_ext.carray'>\n",
      "(51000, 224, 224, 3) (51000, 3) <class 'bcolz.carray_ext.carray'>\n",
      "(368586, 224, 224, 3) (368586, 3) <class 'bcolz.carray_ext.carray'>\n"
     ]
    }
   ],
   "source": [
    "# read bcolz data\n",
    "bclz_valid_data = bcolz.carray(rootdir= valid_name+'_data.bclz', mode='r')\n",
    "bclz_test_data = bcolz.carray(rootdir= test_name + '_data.bclz', mode='r')\n",
    "bclz_train_data = bcolz.carray(rootdir= train_name+ '_data.bclz', mode='r')\n",
    "\n",
    "\n",
    "bclz_valid_labels = bcolz.carray(rootdir= valid_name+'_labels.bclz', mode='r')\n",
    "bclz_test_labels = bcolz.carray(rootdir= test_name + '_labels.bclz', mode='r')\n",
    "bclz_train_labels = bcolz.carray(rootdir= train_name+ '_labels.bclz', mode='r')\n",
    "\n",
    "print(bclz_valid_data.shape, bclz_valid_labels.shape, type(bclz_valid_data))\n",
    "print(bclz_test_data.shape, bclz_test_labels.shape, type(bclz_test_data)) \n",
    "print(bclz_train_data.shape, bclz_train_labels.shape, type(bclz_train_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 224, 224, 3) (255, 3) <class 'numpy.ndarray'>\n",
      "(255, 224, 224, 3) (255, 3) <class 'numpy.ndarray'>\n",
      "(1842, 224, 224, 3) (1842, 3) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# take percentage of data if required\n",
    "bclz_valid_data3 = bclz_valid_data\n",
    "bclz_test_data3 = bclz_test_data\n",
    "bclz_train_data3 = bclz_train_data\n",
    "\n",
    "bclz_valid_labels3 = bclz_valid_labels\n",
    "bclz_test_labels3 = bclz_test_labels\n",
    "bclz_train_labels3 = bclz_train_labels\n",
    "\n",
    "valid_len = int(len(bclz_valid_data) * percent)\n",
    "test_len = int(len(bclz_test_data) * percent)\n",
    "train_len = int(len(bclz_train_data) * percent)\n",
    "    \n",
    "if percent < 1:\n",
    "    bclz_valid_data3 = bclz_valid_data[:valid_len]\n",
    "    bclz_test_data3 = bclz_test_data[:test_len]\n",
    "    bclz_train_data3 = bclz_train_data[:train_len]\n",
    "\n",
    "    bclz_valid_labels3 = bclz_valid_labels[:valid_len]\n",
    "    bclz_test_labels3 = bclz_test_labels[:test_len]\n",
    "    bclz_train_labels3 = bclz_train_labels[:train_len]\n",
    "    \n",
    "print(bclz_valid_data3.shape, bclz_valid_labels3.shape, type(bclz_valid_data3))\n",
    "print(bclz_test_data3.shape, bclz_test_labels3.shape, type(bclz_test_data3))\n",
    "print(bclz_train_data3.shape, bclz_train_labels3.shape, type(bclz_train_data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen =bcolz_data_generator(bclz_valid_data3, bclz_valid_labels3, batch_size=batch_size, shuffle=True)\n",
    "test_gen =bcolz_data_generator(bclz_test_data3, bclz_test_labels3, batch_size=batch_size, shuffle=True)\n",
    "train_gen =bcolz_data_generator(bclz_train_data3, bclz_train_labels3, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg19 = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer\n",
    "#dp1 = Dropout(0.5, name=\"dropout1\")(vgg19.layers[-3].output)\n",
    "#dp2 = Dropout(0.5, name=\"dropout2\")(vgg19.layers[-2].output)\n",
    "x = Dense(num_classes, activation='softmax', name='my_predictions')(vgg19.layers[-2].output)\n",
    "\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#my_model = Model(inputs=vgg19.input, outputs=[dp1])\n",
    "#my_model2 = Model(inputs=vgg19.input, outputs=dp2)\n",
    "#my_model3 = Model(inputs=vgg19.input, outputs=x)\n",
    "#my_model3.summary()\n",
    "#Then create the corresponding model \n",
    "my_model = Model(inputs=vgg19.input, outputs=x)\n",
    "my_model.layers[-3].trainable = True\n",
    "my_model.layers[-2].trainable = True\n",
    "my_model.layers[-1].trainable = True\n",
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "my_predictions (Dense)       (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 139,582,531\n",
      "Trainable params: 119,558,147\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# experimental stuff\n",
    "# Generate a model with all layers (with top)\n",
    "vgg19 = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "x = Dropout(0.5,name=\"dropout1\")(vgg19.layers[-3].output)\n",
    "x = vgg19.layers[-2](x)\n",
    "x = Dropout(0.5,name=\"dropout2\")(x)\n",
    "x = Dense(num_classes, activation='softmax', name='my_predictions')(x)\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "my_model = Model(inputs=vgg19.input, outputs=x)\n",
    "\n",
    "my_model.layers[-5].trainable = True\n",
    "my_model.layers[-3].trainable = True\n",
    "my_model.layers[-1].trainable = True\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in my_model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        layer.kernel_regularizer= regularizers.l2(l2_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False <keras.regularizers.L1L2 object at 0x7f03485fdac8>\n",
      "block1_conv2 False <keras.regularizers.L1L2 object at 0x7f03485fde80>\n",
      "block1_pool False\n",
      "block2_conv1 False <keras.regularizers.L1L2 object at 0x7f03485fd860>\n",
      "block2_conv2 False <keras.regularizers.L1L2 object at 0x7f03485fd898>\n",
      "block2_pool False\n",
      "block3_conv1 False <keras.regularizers.L1L2 object at 0x7f03485fd9e8>\n",
      "block3_conv2 False <keras.regularizers.L1L2 object at 0x7f03485fdfd0>\n",
      "block3_conv3 False <keras.regularizers.L1L2 object at 0x7f03485fd588>\n",
      "block3_conv4 False <keras.regularizers.L1L2 object at 0x7f03485fd4e0>\n",
      "block3_pool False\n",
      "block4_conv1 False <keras.regularizers.L1L2 object at 0x7f03485fd9b0>\n",
      "block4_conv2 False <keras.regularizers.L1L2 object at 0x7f03485fda20>\n",
      "block4_conv3 False <keras.regularizers.L1L2 object at 0x7f03485fdd68>\n",
      "block4_conv4 False <keras.regularizers.L1L2 object at 0x7f034860ce80>\n",
      "block4_pool False\n",
      "block5_conv1 False <keras.regularizers.L1L2 object at 0x7f034860c940>\n",
      "block5_conv2 False <keras.regularizers.L1L2 object at 0x7f034860c668>\n",
      "block5_conv3 False <keras.regularizers.L1L2 object at 0x7f034860c978>\n",
      "block5_conv4 False <keras.regularizers.L1L2 object at 0x7f034860cbe0>\n",
      "block5_pool False\n",
      "flatten False\n",
      "fc1 True <keras.regularizers.L1L2 object at 0x7f034860c518>\n",
      "dropout1 True\n",
      "fc2 True <keras.regularizers.L1L2 object at 0x7f034860cc50>\n",
      "dropout2 True\n",
      "my_predictions True <keras.regularizers.L1L2 object at 0x7f034860cdd8>\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        print(layer.name, layer.trainable,  layer.kernel_regularizer)\n",
    "    else:\n",
    "         print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## do not enable it\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_model.fit_generator(\n",
    "#my_model.fit(\n",
    "          train_gen,\n",
    "          steps_per_epoch= (1 + int(train_len // batch_size)),\n",
    "          #bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(valid_len // batch_size)),\n",
    "          #validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 True\n",
      "block1_conv1 True\n",
      "block1_conv2 True\n",
      "block1_pool True\n",
      "block2_conv1 True\n",
      "block2_conv2 True\n",
      "block2_pool True\n",
      "block3_conv1 True\n",
      "block3_conv2 True\n",
      "block3_conv3 True\n",
      "block3_conv4 True\n",
      "block3_pool True\n",
      "block4_conv1 True\n",
      "block4_conv2 True\n",
      "block4_conv3 True\n",
      "block4_conv4 True\n",
      "block4_pool True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_conv4 True\n",
      "block5_pool True\n",
      "flatten True\n",
      "fc1 True\n",
      "dropout1 True\n",
      "fc2 True\n",
      "dropout2 True\n",
      "my_predictions True\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'saved_models/test_all_layers_caffe_vgg19_weights.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-98ef4ce2613c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-tnf92dft-build/h5py/_objects.c:2853)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-tnf92dft-build/h5py/_objects.c:2811)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/tmp/pip-tnf92dft-build/h5py/h5f.c:2099)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'saved_models/test_all_layers_caffe_vgg19_weights.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "my_model.load_weights(model_path)\n",
    "my_model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-05cc8348110f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m my_model.fit_generator(train_gen,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbclz_train_data3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbclz_valid_data3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_gen' is not defined"
     ]
    }
   ],
   "source": [
    "my_model.fit_generator(train_gen,\n",
    "          steps_per_epoch= (1 + int(bclz_train_data3.shape[0] // batch_size)),\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(bclz_valid_data3.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1670 samples, validate on 208 samples\n",
      "Epoch 1/15\n",
      "1670/1670 [==============================] - 18s 11ms/step - loss: 1.0422 - acc: 0.7832 - val_loss: 0.6154 - val_acc: 0.8413\n",
      "Epoch 2/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.2228 - acc: 0.9515 - val_loss: 0.4027 - val_acc: 0.9327\n",
      "Epoch 3/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.0384 - acc: 0.9874 - val_loss: 0.5005 - val_acc: 0.9038\n",
      "Epoch 4/15\n",
      "1670/1670 [==============================] - 16s 9ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.4818 - val_acc: 0.9135\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1168e9f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "my_model.fit(bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[early_stopping, lrscheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
