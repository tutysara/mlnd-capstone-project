{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bcolz\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from bcolzutils import *\n",
    "from util import *\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"vgg19\"\n",
    "\n",
    "#percent = 0.25\n",
    "percent = 1\n",
    "epochs=15\n",
    "num_classes = 133\n",
    "#batch_size = 48\n",
    "batch_size = 64\n",
    "lr=1e-3\n",
    "momentum=0.9\n",
    "#weight_decay = 1e-5\n",
    "weight_decay = 1e-5\n",
    "test_prefix=\"\"\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" divides the lr by 10 every 5 epochs\"\"\"\n",
    "    n = epoch // 5\n",
    "    return lr / (10 ** n)\n",
    "\n",
    "if percent < 1:\n",
    "    test_prefix = \"test\"\n",
    "    \n",
    "model_path = f'../saved_models/weights.best.fc_layers.{arch}_{test_prefix}.hdf5'\n",
    "loss_history_csv_name = f'fc_layers.{arch}_loss_history_{test_prefix}.csv'\n",
    "\n",
    "d = datetime.datetime.today()\n",
    "\n",
    "logging.basicConfig(level='DEBUG',\n",
    "                    handlers=[\n",
    "                              logging.StreamHandler()])\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "\n",
    "train_name = basedir + '/pp_train_data'\n",
    "valid_name = basedir + '/pp_valid_data'\n",
    "test_name = basedir + '/pp_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 556\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[0m\u001b[01;34mbottleneck_features_vgg19_test_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_test_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:12 \u001b[01;34mbottleneck_features_vgg19_test_y_pred.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:12 \u001b[01;34mbottleneck_features_vgg19_test_y_true.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_train_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_train_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_valid_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_valid_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_test_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_test_data_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_train_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_train_data_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_valid_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_valid_data_labels.bclz\u001b[0m/\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mtest\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtest_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtest_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara  45864 Dec 24 15:27 test_list.txt\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mtrain\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtrain_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtrain_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara 373348 Dec 24 15:25 train_list.txt\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mvalid\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mvalid_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mvalid_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara  46664 Dec 24 15:26 valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -l {basedir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 224, 224, 3) (835, 133) <class 'bcolz.carray_ext.carray'>\n",
      "(836, 224, 224, 3) (836, 133) <class 'bcolz.carray_ext.carray'>\n",
      "(6680, 224, 224, 3) (6680, 133) <class 'bcolz.carray_ext.carray'>\n"
     ]
    }
   ],
   "source": [
    "# read bcolz data\n",
    "bclz_valid_data = bcolz.carray(rootdir= valid_name+'_data.bclz', mode='r')\n",
    "bclz_test_data = bcolz.carray(rootdir= test_name + '_data.bclz', mode='r')\n",
    "bclz_train_data = bcolz.carray(rootdir= train_name+ '_data.bclz', mode='r')\n",
    "\n",
    "\n",
    "bclz_valid_labels = bcolz.carray(rootdir= valid_name+'_labels.bclz', mode='r')\n",
    "bclz_test_labels = bcolz.carray(rootdir= test_name + '_labels.bclz', mode='r')\n",
    "bclz_train_labels = bcolz.carray(rootdir= train_name+ '_labels.bclz', mode='r')\n",
    "\n",
    "print(bclz_valid_data.shape, bclz_valid_labels.shape, type(bclz_valid_data))\n",
    "print(bclz_test_data.shape, bclz_test_labels.shape, type(bclz_test_data)) \n",
    "print(bclz_train_data.shape, bclz_train_labels.shape, type(bclz_train_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 224, 224, 3) (835, 133) <class 'bcolz.carray_ext.carray'>\n",
      "(836, 224, 224, 3) (836, 133) <class 'bcolz.carray_ext.carray'>\n",
      "(6680, 224, 224, 3) (6680, 133) <class 'bcolz.carray_ext.carray'>\n"
     ]
    }
   ],
   "source": [
    "# take percentage of data if required\n",
    "bclz_valid_data3 = bclz_valid_data\n",
    "bclz_test_data3 = bclz_test_data\n",
    "bclz_train_data3 = bclz_train_data\n",
    "\n",
    "bclz_valid_labels3 = bclz_valid_labels\n",
    "bclz_test_labels3 = bclz_test_labels\n",
    "bclz_train_labels3 = bclz_train_labels\n",
    "\n",
    "valid_len = int(len(bclz_valid_data) * percent)\n",
    "test_len = int(len(bclz_test_data) * percent)\n",
    "train_len = int(len(bclz_train_data) * percent)\n",
    "    \n",
    "if percent < 1:\n",
    "    bclz_valid_data3 = bclz_valid_data[:valid_len]\n",
    "    bclz_test_data3 = bclz_test_data[:test_len]\n",
    "    bclz_train_data3 = bclz_train_data[:train_len]\n",
    "\n",
    "    bclz_valid_labels3 = bclz_valid_labels[:valid_len]\n",
    "    bclz_test_labels3 = bclz_test_labels[:test_len]\n",
    "    bclz_train_labels3 = bclz_train_labels[:train_len]\n",
    "    \n",
    "print(bclz_valid_data3.shape, bclz_valid_labels3.shape, type(bclz_valid_data3))\n",
    "print(bclz_test_data3.shape, bclz_test_labels3.shape, type(bclz_test_data3))\n",
    "print(bclz_train_data3.shape, bclz_train_labels3.shape, type(bclz_train_data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen =bcolz_data_generator(bclz_valid_data3, bclz_valid_labels3, batch_size=batch_size, shuffle=True)\n",
    "test_gen =bcolz_data_generator(bclz_test_data3, bclz_test_labels3, batch_size=batch_size, shuffle=True)\n",
    "train_gen =bcolz_data_generator(bclz_train_data3, bclz_train_labels3, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg19 = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer\n",
    "#dp1 = Dropout(0.5, name=\"dropout1\")(vgg19.layers[-3].output)\n",
    "#dp2 = Dropout(0.5, name=\"dropout2\")(vgg19.layers[-2].output)\n",
    "x = Dense(num_classes, activation='softmax', name='my_predictions')(vgg19.layers[-2].output)\n",
    "\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#my_model = Model(inputs=vgg19.input, outputs=[dp1])\n",
    "#my_model2 = Model(inputs=vgg19.input, outputs=dp2)\n",
    "#my_model3 = Model(inputs=vgg19.input, outputs=x)\n",
    "#my_model3.summary()\n",
    "#Then create the corresponding model \n",
    "my_model = Model(inputs=vgg19.input, outputs=x)\n",
    "my_model.layers[-3].trainable = True\n",
    "my_model.layers[-2].trainable = True\n",
    "my_model.layers[-1].trainable = True\n",
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental stuff\n",
    "# Generate a model with all layers (with top)\n",
    "vgg19 = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "x = Dropout(0.5,name=\"dropout1\")(vgg19.layers[-3].output)\n",
    "x = vgg19.layers[-2](x)\n",
    "x = Dropout(0.5,name=\"dropout2\")(x)\n",
    "x = Dense(num_classes, activation='softmax', name='my_predictions')(x)\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "my_model = Model(inputs=vgg19.input, outputs=x)\n",
    "\n",
    "my_model.layers[-5].trainable = True\n",
    "my_model.layers[-3].trainable = True\n",
    "my_model.layers[-1].trainable = True\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "my_predictions (Dense)       (None, 133)               544901    \n",
      "=================================================================\n",
      "Total params: 140,115,141\n",
      "Trainable params: 120,090,757\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in my_model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        layer.kernel_regularizer= regularizers.l2(weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False <keras.regularizers.L1L2 object at 0x7fa4819a1588>\n",
      "block1_conv2 False <keras.regularizers.L1L2 object at 0x7fa4819a1198>\n",
      "block1_pool False\n",
      "block2_conv1 False <keras.regularizers.L1L2 object at 0x7fa4819a10f0>\n",
      "block2_conv2 False <keras.regularizers.L1L2 object at 0x7fa4819a15f8>\n",
      "block2_pool False\n",
      "block3_conv1 False <keras.regularizers.L1L2 object at 0x7fa4819a14a8>\n",
      "block3_conv2 False <keras.regularizers.L1L2 object at 0x7fa4819a1550>\n",
      "block3_conv3 False <keras.regularizers.L1L2 object at 0x7fa4819a1400>\n",
      "block3_conv4 False <keras.regularizers.L1L2 object at 0x7fa4819a1470>\n",
      "block3_pool False\n",
      "block4_conv1 False <keras.regularizers.L1L2 object at 0x7fa4819a15c0>\n",
      "block4_conv2 False <keras.regularizers.L1L2 object at 0x7fa4819a14e0>\n",
      "block4_conv3 False <keras.regularizers.L1L2 object at 0x7fa4819a1518>\n",
      "block4_conv4 False <keras.regularizers.L1L2 object at 0x7fa4819a1438>\n",
      "block4_pool False\n",
      "block5_conv1 False <keras.regularizers.L1L2 object at 0x7fa4819a1780>\n",
      "block5_conv2 False <keras.regularizers.L1L2 object at 0x7fa4819a1630>\n",
      "block5_conv3 False <keras.regularizers.L1L2 object at 0x7fa4819a17b8>\n",
      "block5_conv4 False <keras.regularizers.L1L2 object at 0x7fa4819a1828>\n",
      "block5_pool False\n",
      "flatten False\n",
      "fc1 True <keras.regularizers.L1L2 object at 0x7fa4819a1668>\n",
      "dropout1 True\n",
      "fc2 True <keras.regularizers.L1L2 object at 0x7fa4819a17f0>\n",
      "dropout2 True\n",
      "my_predictions True <keras.regularizers.L1L2 object at 0x7fa4819a16d8>\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        print(layer.name, layer.trainable,  layer.kernel_regularizer)\n",
    "    else:\n",
    "         print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "105/105 [==============================] - 56s 533ms/step - loss: 2.7627 - acc: 0.4115 - val_loss: 1.1033 - val_acc: 0.6898\n",
      "Epoch 2/15\n",
      "105/105 [==============================] - 52s 494ms/step - loss: 1.1317 - acc: 0.6943 - val_loss: 0.9922 - val_acc: 0.6970\n",
      "Epoch 3/15\n",
      "105/105 [==============================] - 52s 494ms/step - loss: 0.7583 - acc: 0.7907 - val_loss: 0.8813 - val_acc: 0.7365\n",
      "Epoch 4/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.5328 - acc: 0.8484 - val_loss: 0.8017 - val_acc: 0.7808\n",
      "Epoch 5/15\n",
      "105/105 [==============================] - 52s 494ms/step - loss: 0.3468 - acc: 0.9010 - val_loss: 0.8447 - val_acc: 0.7713\n",
      "Epoch 6/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.2932 - acc: 0.9190 - val_loss: 0.7584 - val_acc: 0.8000\n",
      "Epoch 7/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.1711 - acc: 0.9481 - val_loss: 0.7606 - val_acc: 0.7856\n",
      "Epoch 8/15\n",
      "105/105 [==============================] - 52s 496ms/step - loss: 0.1305 - acc: 0.9584 - val_loss: 0.7284 - val_acc: 0.8048\n",
      "Epoch 9/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.1108 - acc: 0.9681 - val_loss: 0.7817 - val_acc: 0.7940\n",
      "Epoch 10/15\n",
      "105/105 [==============================] - 52s 496ms/step - loss: 0.0948 - acc: 0.9708 - val_loss: 0.7462 - val_acc: 0.7772\n",
      "Epoch 11/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.0922 - acc: 0.9730 - val_loss: 0.7135 - val_acc: 0.7988\n",
      "Epoch 12/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.0907 - acc: 0.9734 - val_loss: 0.7386 - val_acc: 0.8012\n",
      "Epoch 13/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.0860 - acc: 0.9764 - val_loss: 0.7012 - val_acc: 0.7964\n",
      "Epoch 14/15\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.0795 - acc: 0.9762 - val_loss: 0.7241 - val_acc: 0.8012\n",
      "Epoch 15/15\n",
      "105/105 [==============================] - 52s 496ms/step - loss: 0.0770 - acc: 0.9752 - val_loss: 0.7243 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4434d1b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_model.fit_generator(\n",
    "#my_model.fit(\n",
    "          train_gen,\n",
    "          steps_per_epoch= (1 + int(train_len // batch_size)),\n",
    "          #bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(valid_len // batch_size)),\n",
    "          #validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 True\n",
      "block1_conv1 True\n",
      "block1_conv2 True\n",
      "block1_pool True\n",
      "block2_conv1 True\n",
      "block2_conv2 True\n",
      "block2_pool True\n",
      "block3_conv1 True\n",
      "block3_conv2 True\n",
      "block3_conv3 True\n",
      "block3_conv4 True\n",
      "block3_pool True\n",
      "block4_conv1 True\n",
      "block4_conv2 True\n",
      "block4_conv3 True\n",
      "block4_conv4 True\n",
      "block4_pool True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_conv4 True\n",
      "block5_pool True\n",
      "flatten True\n",
      "fc1 True\n",
      "fc2 True\n",
      "my_predictions True\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "27/27 [==============================] - 14s 528ms/step - loss: 0.2139 - acc: 0.9368 - val_loss: 0.8574 - val_acc: 0.8365\n",
      "Epoch 2/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 0.5421 - acc: 0.8772 - val_loss: 0.5114 - val_acc: 0.8702\n",
      "Epoch 3/15\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 0.1462 - acc: 0.9525 - val_loss: 0.4752 - val_acc: 0.8894\n",
      "Epoch 4/15\n",
      "27/27 [==============================] - 14s 528ms/step - loss: 0.0295 - acc: 0.9925 - val_loss: 0.4126 - val_acc: 0.8894\n",
      "Epoch 5/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.3972 - val_acc: 0.8942\n",
      "Epoch 6/15\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3986 - val_acc: 0.8990\n",
      "Epoch 7/15\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3983 - val_acc: 0.8990\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda4846c1d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit_generator(train_gen,\n",
    "          steps_per_epoch= (1 + int(bclz_train_data3.shape[0] // batch_size)),\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(bclz_valid_data3.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1670 samples, validate on 208 samples\n",
      "Epoch 1/15\n",
      "1670/1670 [==============================] - 18s 11ms/step - loss: 1.0422 - acc: 0.7832 - val_loss: 0.6154 - val_acc: 0.8413\n",
      "Epoch 2/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.2228 - acc: 0.9515 - val_loss: 0.4027 - val_acc: 0.9327\n",
      "Epoch 3/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.0384 - acc: 0.9874 - val_loss: 0.5005 - val_acc: 0.9038\n",
      "Epoch 4/15\n",
      "1670/1670 [==============================] - 16s 9ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.4818 - val_acc: 0.9135\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1168e9f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "my_model.fit(bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[early_stopping, lrscheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
