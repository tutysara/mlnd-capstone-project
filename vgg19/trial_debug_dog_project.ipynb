{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bcolz\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from bcolzutils import *\n",
    "from util import *\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"vgg19\"\n",
    "\n",
    "percent = 0.25\n",
    "#percent = 1\n",
    "epochs=15\n",
    "num_classes = 133\n",
    "batch_size = 48\n",
    "lr=1e-3\n",
    "momentum=0.9\n",
    "weight_decay = 1e-5\n",
    "test_prefix=\"\"\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" divides the lr by 10 every 5 epochs\"\"\"\n",
    "    n = epoch // 5\n",
    "    return lr / (10 ** n)\n",
    "\n",
    "if percent < 1:\n",
    "    test_prefix = \"test\"\n",
    "    \n",
    "model_path = f'../saved_models/weights.best.fc_layers.{arch}_{test_prefix}.hdf5'\n",
    "loss_history_csv_name = f'fc_layers.{arch}_loss_history_{test_prefix}.csv'\n",
    "\n",
    "d = datetime.datetime.today()\n",
    "\n",
    "logging.basicConfig(level='DEBUG',\n",
    "                    handlers=[\n",
    "                              logging.StreamHandler()])\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "\n",
    "train_name = basedir + '/pp_train_data'\n",
    "valid_name = basedir + '/pp_valid_data'\n",
    "test_name = basedir + '/pp_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 556\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[0m\u001b[01;34mbottleneck_features_vgg19_test_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_test_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:12 \u001b[01;34mbottleneck_features_vgg19_test_y_pred.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:12 \u001b[01;34mbottleneck_features_vgg19_test_y_true.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_train_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_train_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_valid_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_valid_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_test_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_test_data_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_train_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_train_data_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_valid_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  6 18:57 \u001b[01;34mpp_valid_data_labels.bclz\u001b[0m/\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mtest\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtest_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtest_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara  45864 Dec 24 15:27 test_list.txt\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mtrain\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtrain_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtrain_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara 373348 Dec 24 15:25 train_list.txt\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mvalid\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mvalid_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mvalid_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara  46664 Dec 24 15:26 valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -l {basedir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 224, 224, 3) (835, 133)\n",
      "(836, 224, 224, 3) (836, 133)\n",
      "(6680, 224, 224, 3) (6680, 133)\n"
     ]
    }
   ],
   "source": [
    "# read bcolz data\n",
    "bclz_valid_data = bcolz.carray(rootdir= valid_name+'_data.bclz', mode='r')\n",
    "bclz_test_data = bcolz.carray(rootdir= test_name + '_data.bclz', mode='r')\n",
    "bclz_train_data = bcolz.carray(rootdir= train_name+ '_data.bclz', mode='r')\n",
    "\n",
    "\n",
    "bclz_valid_labels = bcolz.carray(rootdir= valid_name+'_labels.bclz', mode='r')\n",
    "bclz_test_labels = bcolz.carray(rootdir= test_name + '_labels.bclz', mode='r')\n",
    "bclz_train_labels = bcolz.carray(rootdir= train_name+ '_labels.bclz', mode='r')\n",
    "\n",
    "print(bclz_valid_data.shape, bclz_valid_labels.shape)\n",
    "print(bclz_test_data.shape, bclz_test_labels.shape) \n",
    "print(bclz_train_data.shape, bclz_train_labels.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 224, 224, 3) (208, 133)\n",
      "(209, 224, 224, 3) (209, 133)\n",
      "(1670, 224, 224, 3) (1670, 133)\n"
     ]
    }
   ],
   "source": [
    "# take percentage of data if required\n",
    "bclz_valid_data3 = bclz_valid_data\n",
    "bclz_test_data3 = bclz_test_data\n",
    "bclz_train_data3 = bclz_train_data\n",
    "\n",
    "bclz_valid_labels3 = bclz_valid_labels\n",
    "bclz_test_labels3 = bclz_test_labels\n",
    "bclz_train_labels3 = bclz_train_labels\n",
    "    \n",
    "if percent < 1:\n",
    "    valid_len = int(len(bclz_valid_data) * percent)\n",
    "    test_len = int(len(bclz_test_data) * percent)\n",
    "    train_len = int(len(bclz_train_data) * percent)\n",
    "\n",
    "    bclz_valid_data3 = bclz_valid_data[:valid_len]\n",
    "    bclz_test_data3 = bclz_test_data[:test_len]\n",
    "    bclz_train_data3 = bclz_train_data[:train_len]\n",
    "\n",
    "    bclz_valid_labels3 = bclz_valid_labels[:valid_len]\n",
    "    bclz_test_labels3 = bclz_test_labels[:test_len]\n",
    "    bclz_train_labels3 = bclz_train_labels[:train_len]\n",
    "    \n",
    "print(bclz_valid_data3.shape, bclz_valid_labels3.shape)\n",
    "print(bclz_test_data3.shape, bclz_test_labels3.shape)\n",
    "print(bclz_train_data3.shape, bclz_train_labels3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen =bcolz_data_generator(bclz_valid_data3, bclz_valid_labels3, batch_size=batch_size, shuffle=True)\n",
    "test_gen =bcolz_data_generator(bclz_test_data3, bclz_test_labels3, batch_size=batch_size, shuffle=True)\n",
    "train_gen =bcolz_data_generator(bclz_train_data3, bclz_train_labels3, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"my...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg19 = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(num_classes, activation='softmax', name='my_predictions')(vgg19.layers[-2].output)\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#Then create the corresponding model \n",
    "my_model = Model(input=vgg19.input, output=x)\n",
    "my_model.layers[-3].trainable = True\n",
    "my_model.layers[-2].trainable = True\n",
    "my_model.layers[-1].trainable = True\n",
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in my_model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        layer.kernel_regularizer= regularizers.l2(weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False <keras.regularizers.L1L2 object at 0x7f37b844a198>\n",
      "block1_conv2 False <keras.regularizers.L1L2 object at 0x7f37b844a1d0>\n",
      "block1_pool False\n",
      "block2_conv1 False <keras.regularizers.L1L2 object at 0x7f37b844a0f0>\n",
      "block2_conv2 False <keras.regularizers.L1L2 object at 0x7f37b844a128>\n",
      "block2_pool False\n",
      "block3_conv1 False <keras.regularizers.L1L2 object at 0x7f37b844a048>\n",
      "block3_conv2 False <keras.regularizers.L1L2 object at 0x7f37b844a208>\n",
      "block3_conv3 False <keras.regularizers.L1L2 object at 0x7f37b844a2e8>\n",
      "block3_conv4 False <keras.regularizers.L1L2 object at 0x7f37b844a390>\n",
      "block3_pool False\n",
      "block4_conv1 False <keras.regularizers.L1L2 object at 0x7f37b844a320>\n",
      "block4_conv2 False <keras.regularizers.L1L2 object at 0x7f37b844a358>\n",
      "block4_conv3 False <keras.regularizers.L1L2 object at 0x7f37b844a278>\n",
      "block4_conv4 False <keras.regularizers.L1L2 object at 0x7f37b844a2b0>\n",
      "block4_pool False\n",
      "block5_conv1 False <keras.regularizers.L1L2 object at 0x7f37b844a240>\n",
      "block5_conv2 False <keras.regularizers.L1L2 object at 0x7f37b844a3c8>\n",
      "block5_conv3 False <keras.regularizers.L1L2 object at 0x7f37b844a438>\n",
      "block5_conv4 False <keras.regularizers.L1L2 object at 0x7f37b844a4a8>\n",
      "block5_pool False\n",
      "flatten False\n",
      "fc1 True <keras.regularizers.L1L2 object at 0x7f37b844a4e0>\n",
      "fc2 True <keras.regularizers.L1L2 object at 0x7f37b844a518>\n",
      "my_predictions True <keras.regularizers.L1L2 object at 0x7f37b844a550>\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        print(layer.name, layer.trainable,  layer.kernel_regularizer)\n",
    "    else:\n",
    "         print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "35/35 [==============================] - 18s 510ms/step - loss: 1.1413 - acc: 0.7501 - val_loss: 0.4201 - val_acc: 0.9135\n",
      "Epoch 2/15\n",
      "35/35 [==============================] - 13s 386ms/step - loss: 0.0611 - acc: 0.9809 - val_loss: 0.4336 - val_acc: 0.8942\n",
      "Epoch 3/15\n",
      "35/35 [==============================] - 13s 386ms/step - loss: 0.0143 - acc: 0.9940 - val_loss: 0.5376 - val_acc: 0.8942\n",
      "Epoch 4/15\n",
      "35/35 [==============================] - 13s 384ms/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.4231 - val_acc: 0.9135\n",
      "Epoch 5/15\n",
      "35/35 [==============================] - 14s 386ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.4496 - val_acc: 0.9183\n",
      "Epoch 6/15\n",
      "35/35 [==============================] - 13s 384ms/step - loss: 6.4030e-04 - acc: 1.0000 - val_loss: 0.4518 - val_acc: 0.9183\n",
      "Epoch 7/15\n",
      "35/35 [==============================] - 14s 386ms/step - loss: 6.1876e-04 - acc: 1.0000 - val_loss: 0.4515 - val_acc: 0.9183\n",
      "Epoch 8/15\n",
      " 5/35 [===>..........................] - ETA: 10s - loss: 4.8547e-04 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fb786dc7acd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_len\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0;31m#validation_data=(bclz_valid_data3, bclz_valid_labels3),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           callbacks=[lrscheduler] )\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dog-project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_model.fit_generator(\n",
    "#my_model.fit(\n",
    "          train_gen,\n",
    "          steps_per_epoch= (1 + int(train_len // batch_size)),\n",
    "          #bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(valid_len // batch_size)),\n",
    "          #validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 True\n",
      "block1_conv1 True\n",
      "block1_conv2 True\n",
      "block1_pool True\n",
      "block2_conv1 True\n",
      "block2_conv2 True\n",
      "block2_pool True\n",
      "block3_conv1 True\n",
      "block3_conv2 True\n",
      "block3_conv3 True\n",
      "block3_conv4 True\n",
      "block3_pool True\n",
      "block4_conv1 True\n",
      "block4_conv2 True\n",
      "block4_conv3 True\n",
      "block4_conv4 True\n",
      "block4_pool True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_conv4 True\n",
      "block5_pool True\n",
      "flatten True\n",
      "fc1 True\n",
      "fc2 True\n",
      "my_predictions True\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "27/27 [==============================] - 14s 528ms/step - loss: 0.2139 - acc: 0.9368 - val_loss: 0.8574 - val_acc: 0.8365\n",
      "Epoch 2/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 0.5421 - acc: 0.8772 - val_loss: 0.5114 - val_acc: 0.8702\n",
      "Epoch 3/15\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 0.1462 - acc: 0.9525 - val_loss: 0.4752 - val_acc: 0.8894\n",
      "Epoch 4/15\n",
      "27/27 [==============================] - 14s 528ms/step - loss: 0.0295 - acc: 0.9925 - val_loss: 0.4126 - val_acc: 0.8894\n",
      "Epoch 5/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.3972 - val_acc: 0.8942\n",
      "Epoch 6/15\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3986 - val_acc: 0.8990\n",
      "Epoch 7/15\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3983 - val_acc: 0.8990\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda4846c1d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit_generator(train_gen,\n",
    "          steps_per_epoch= (1 + int(bclz_train_data3.shape[0] // batch_size)),\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(bclz_valid_data3.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1670 samples, validate on 208 samples\n",
      "Epoch 1/15\n",
      "1670/1670 [==============================] - 18s 11ms/step - loss: 1.0422 - acc: 0.7832 - val_loss: 0.6154 - val_acc: 0.8413\n",
      "Epoch 2/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.2228 - acc: 0.9515 - val_loss: 0.4027 - val_acc: 0.9327\n",
      "Epoch 3/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.0384 - acc: 0.9874 - val_loss: 0.5005 - val_acc: 0.9038\n",
      "Epoch 4/15\n",
      "1670/1670 [==============================] - 16s 9ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.4818 - val_acc: 0.9135\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1168e9f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "my_model.fit(bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[early_stopping, lrscheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
