{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bcolz\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from bcolzutils import *\n",
    "from util import *\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2 \n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobile_preprocess_input\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"vgg19\"\n",
    "\n",
    "percent = 0.25\n",
    "#percent = 1\n",
    "epochs=15\n",
    "num_classes = 133\n",
    "batch_size = 64\n",
    "lr=1e-3\n",
    "momentum=0.85\n",
    "weight_decay = 1e-5\n",
    "test_prefix=\"\"\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" divides the lr by 10 every 5 epochs\"\"\"\n",
    "    n = epoch // 5\n",
    "    return lr * (0.1 ** n)\n",
    "\n",
    "if percent < 1:\n",
    "    test_prefix = \"_test\"\n",
    "    \n",
    "test_result = f'bottleneck_features_{arch}_result{test_prefix}.npz'\n",
    "model_path = f'../saved_models/weights.best.topmodel.{arch}{test_prefix}.hdf5'\n",
    "loss_history_csv_name = f'train_top_model_{arch}_loss_history{test_prefix}.csv'\n",
    "\n",
    "d = datetime.datetime.today()\n",
    "\n",
    "logging.basicConfig(level='DEBUG',\n",
    "                    handlers=[\n",
    "                              logging.StreamHandler()])\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "\n",
    "\n",
    "train_name = basedir + '/train_data'\n",
    "valid_name = basedir + '/valid_data'\n",
    "test_name = basedir + '/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 532\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[0m\u001b[01;34mbottleneck_features_vgg19_test_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_test_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:12 \u001b[01;34mbottleneck_features_vgg19_test_y_pred.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:12 \u001b[01;34mbottleneck_features_vgg19_test_y_true.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_train_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_train_labels.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_valid_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 20:00 \u001b[01;34mbottleneck_features_vgg19_valid_labels.bclz\u001b[0m/\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mtest\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtest_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtest_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara  45864 Dec 24 15:27 test_list.txt\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mtrain\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtrain_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mtrain_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara 373348 Dec 24 15:25 train_list.txt\n",
      "drwxr-xr-x 135 tutysara tutysara   4096 Mar 27  2017 \u001b[01;34mvalid\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mvalid_data_data.bclz\u001b[0m/\n",
      "drwxrwxr-x   4 tutysara tutysara   4096 Mar  2 19:52 \u001b[01;34mvalid_data_labels.bclz\u001b[0m/\n",
      "-rw-rw-r--   1 tutysara tutysara  46664 Dec 24 15:26 valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -l {basedir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 224, 224, 3) (835, 133)\n",
      "(836, 224, 224, 3) (836, 133)\n",
      "(6680, 224, 224, 3) (6680, 133)\n"
     ]
    }
   ],
   "source": [
    "#3 read bcolz data\n",
    "bclz_valid_data = bcolz.carray(rootdir= valid_name+'_data.bclz', mode='r')\n",
    "bclz_test_data = bcolz.carray(rootdir= test_name + '_data.bclz', mode='r')\n",
    "bclz_train_data = bcolz.carray(rootdir= train_name+ '_data.bclz', mode='r')\n",
    "\n",
    "\n",
    "bclz_valid_labels = bcolz.carray(rootdir= valid_name+'_labels.bclz', mode='r')\n",
    "bclz_test_labels = bcolz.carray(rootdir= test_name + '_labels.bclz', mode='r')\n",
    "bclz_train_labels = bcolz.carray(rootdir= train_name+ '_labels.bclz', mode='r')\n",
    "\n",
    "print(bclz_valid_data.shape, bclz_valid_labels.shape)\n",
    "print(bclz_test_data.shape, bclz_test_labels.shape) \n",
    "print(bclz_train_data.shape, bclz_train_labels.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"my...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg19 = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(num_classes, activation='softmax', name='my_predictions')(vgg19.layers[-2].output)\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#Then create the corresponding model \n",
    "my_model = Model(input=vgg19.input, output=x)\n",
    "my_model.layers[-3].trainable = True\n",
    "my_model.layers[-2].trainable = True\n",
    "my_model.layers[-1].trainable = True\n",
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_conv4 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_conv4 False\n",
      "block4_pool False\n",
      "block5_conv1 False\n",
      "block5_conv2 False\n",
      "block5_conv3 False\n",
      "block5_conv4 False\n",
      "block5_pool False\n",
      "flatten False\n",
      "fc1 True\n",
      "fc2 True\n",
      "my_predictions True\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 224, 224, 3) (835, 133)\n",
      "(836, 224, 224, 3) (836, 133)\n",
      "(6680, 224, 224, 3) (6680, 133)\n"
     ]
    }
   ],
   "source": [
    "print(bclz_valid_data.shape, bclz_valid_labels.shape)\n",
    "print(bclz_test_data.shape, bclz_test_labels.shape) \n",
    "print(bclz_train_data.shape, bclz_train_labels.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclz_valid_data2 = bclz_valid_data[:int(len(bclz_valid_data) * percent)]\n",
    "bclz_test_data2 = bclz_test_data[:int(len(bclz_test_data) * percent)]\n",
    "bclz_train_data2 = bclz_train_data[:int(len(bclz_train_data) * percent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclz_valid_data3 = vgg19_preprocess_input(bclz_valid_data2)\n",
    "bclz_test_data3 = vgg19_preprocess_input(bclz_test_data2)\n",
    "bclz_train_data3 = vgg19_preprocess_input(bclz_train_data2)\n",
    "\n",
    "bclz_valid_labels3 = bclz_valid_labels[:int(len(bclz_valid_data) * percent)]\n",
    "bclz_test_labels3 = bclz_test_labels[:int(len(bclz_test_labels) * percent)]\n",
    "bclz_train_labels3 = bclz_train_labels[:int(len(bclz_train_labels) * percent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 224, 224, 3) (208, 133)\n",
      "(209, 224, 224, 3) (209, 133)\n",
      "(1670, 224, 224, 3) (1670, 133)\n"
     ]
    }
   ],
   "source": [
    "print(bclz_valid_data3.shape, bclz_valid_labels3.shape)\n",
    "print(bclz_test_data3.shape, bclz_test_labels3.shape)\n",
    "print(bclz_train_data3.shape, bclz_train_labels3.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valid_gen =bcolz_data_generator(bclz_valid_data, bclz_valid_labels, batch_size=batch_size, preprocess=vgg19_preprocess_input)\n",
    "test_gen =bcolz_data_generator(bclz_test_data, bclz_test_labels, batch_size=batch_size, preprocess=vgg19_preprocess_input)\n",
    "train_gen =bcolz_data_generator(bclz_train_data, bclz_train_labels, batch_size=batch_size, preprocess=vgg19_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "valid_gen =bcolz_data_generator(bclz_valid_data3, bclz_valid_labels3, batch_size=batch_size)\n",
    "test_gen =bcolz_data_generator(bclz_test_data3, bclz_test_labels3, batch_size=batch_size)\n",
    "train_gen =bcolz_data_generator(bclz_train_data3, bclz_train_labels3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680 835\n"
     ]
    }
   ],
   "source": [
    "print(bclz_train_data.shape[0], bclz_valid_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "27/27 [==============================] - 18s 653ms/step - loss: 7.1924 - acc: 0.0550 - val_loss: 3.9378 - val_acc: 0.1923\n",
      "Epoch 2/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 4.0966 - acc: 0.2457 - val_loss: 3.3611 - val_acc: 0.4471\n",
      "Epoch 3/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 2.6642 - acc: 0.4573 - val_loss: 2.8071 - val_acc: 0.5673\n",
      "Epoch 4/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 2.5126 - acc: 0.5034 - val_loss: 3.9383 - val_acc: 0.5144\n",
      "Epoch 5/15\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 1.9163 - acc: 0.6738 - val_loss: 1.4708 - val_acc: 0.7452\n",
      "Epoch 6/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 1.3003 - acc: 0.7758 - val_loss: 0.9967 - val_acc: 0.7885\n",
      "Epoch 7/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.5676 - acc: 0.8847 - val_loss: 0.7613 - val_acc: 0.8173\n",
      "Epoch 8/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 0.3444 - acc: 0.9142 - val_loss: 0.6187 - val_acc: 0.8462\n",
      "Epoch 9/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.2257 - acc: 0.9345 - val_loss: 0.5391 - val_acc: 0.8846\n",
      "Epoch 10/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 0.1564 - acc: 0.9681 - val_loss: 0.5011 - val_acc: 0.8894\n",
      "Epoch 11/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.1111 - acc: 0.9803 - val_loss: 0.4968 - val_acc: 0.8894\n",
      "Epoch 12/15\n",
      "27/27 [==============================] - 14s 532ms/step - loss: 0.1121 - acc: 0.9791 - val_loss: 0.4942 - val_acc: 0.8942\n",
      "Epoch 13/15\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 0.1095 - acc: 0.9797 - val_loss: 0.4918 - val_acc: 0.8990\n",
      "Epoch 14/15\n",
      "27/27 [==============================] - 14s 532ms/step - loss: 0.1070 - acc: 0.9803 - val_loss: 0.4895 - val_acc: 0.8990\n",
      "Epoch 15/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 0.1048 - acc: 0.9809 - val_loss: 0.4874 - val_acc: 0.8990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda6a4e96a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_model.fit_generator(train_gen,\n",
    "          steps_per_epoch= (1 + int(bclz_train_data3.shape[0] // batch_size)),\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(bclz_valid_data3.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 True\n",
      "block1_conv1 True\n",
      "block1_conv2 True\n",
      "block1_pool True\n",
      "block2_conv1 True\n",
      "block2_conv2 True\n",
      "block2_pool True\n",
      "block3_conv1 True\n",
      "block3_conv2 True\n",
      "block3_conv3 True\n",
      "block3_conv4 True\n",
      "block3_pool True\n",
      "block4_conv1 True\n",
      "block4_conv2 True\n",
      "block4_conv3 True\n",
      "block4_conv4 True\n",
      "block4_pool True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_conv4 True\n",
      "block5_pool True\n",
      "flatten True\n",
      "fc1 True\n",
      "fc2 True\n",
      "my_predictions True\n"
     ]
    }
   ],
   "source": [
    "for layer in my_model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "27/27 [==============================] - 14s 528ms/step - loss: 0.2139 - acc: 0.9368 - val_loss: 0.8574 - val_acc: 0.8365\n",
      "Epoch 2/15\n",
      "27/27 [==============================] - 14s 530ms/step - loss: 0.5421 - acc: 0.8772 - val_loss: 0.5114 - val_acc: 0.8702\n",
      "Epoch 3/15\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 0.1462 - acc: 0.9525 - val_loss: 0.4752 - val_acc: 0.8894\n",
      "Epoch 4/15\n",
      "27/27 [==============================] - 14s 528ms/step - loss: 0.0295 - acc: 0.9925 - val_loss: 0.4126 - val_acc: 0.8894\n",
      "Epoch 5/15\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.3972 - val_acc: 0.8942\n",
      "Epoch 6/15\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3986 - val_acc: 0.8990\n",
      "Epoch 7/15\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.3983 - val_acc: 0.8990\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda4846c1d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit_generator(train_gen,\n",
    "          steps_per_epoch= (1 + int(bclz_train_data3.shape[0] // batch_size)),\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1 + int(bclz_valid_data3.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, lrscheduler] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1670 samples, validate on 208 samples\n",
      "Epoch 1/15\n",
      "1670/1670 [==============================] - 18s 11ms/step - loss: 1.0422 - acc: 0.7832 - val_loss: 0.6154 - val_acc: 0.8413\n",
      "Epoch 2/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.2228 - acc: 0.9515 - val_loss: 0.4027 - val_acc: 0.9327\n",
      "Epoch 3/15\n",
      "1670/1670 [==============================] - 15s 9ms/step - loss: 0.0384 - acc: 0.9874 - val_loss: 0.5005 - val_acc: 0.9038\n",
      "Epoch 4/15\n",
      "1670/1670 [==============================] - 16s 9ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 0.4818 - val_acc: 0.9135\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1168e9f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "csv_logger = CSVLogger(loss_history_csv_name, append=True, separator=',')\n",
    "lrscheduler = LearningRateScheduler(schedule=lr_schedule)\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "              metrics=['accuracy'])\n",
    "my_model.fit(bclz_train_data3, bclz_train_labels3,\n",
    "          epochs=epochs,\n",
    "          validation_data=(bclz_valid_data3, bclz_valid_labels3),\n",
    "          callbacks=[early_stopping, lrscheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
