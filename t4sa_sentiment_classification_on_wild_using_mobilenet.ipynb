{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Display progress logs on stdout\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG,\n",
    "#                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 75)\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make the csv files for dog project\n",
    "cd dogImages\n",
    "for filename in $(find train|grep .jpg); do\n",
    "    label=$(echo $filename| cut -d'/' -f 2)\n",
    "    label_num=$(echo $label| cut -d'.' -f 1)\n",
    "    echo \"$filename $label_num\"\n",
    "done"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "basedir=\"/home/tutysara/src/myprojects/t4sa/data\"\n",
    "train_idx_path = basedir+ \"/b-t4sa_train.txt\"\n",
    "valid_idx_path = basedir+ \"/b-t4sa_val.txt\"\n",
    "test_idx_path = basedir+ \"/b-t4sa_test.txt\"\n",
    "\n",
    "\n",
    "col_names = [\"X\", \"y\"]\n",
    "percent = 1\n",
    "train_data_df = pd.read_csv(train_idx_path, sep=\" \", header=None, names=col_names)\n",
    "valid_data_df = pd.read_csv(valid_idx_path, sep=\" \", header=None, names=col_names)\n",
    "test_data_df = pd.read_csv(test_idx_path, sep=\" \", header=None, names=col_names)\n",
    "\n",
    "train_data_df = train_data_df[:int(train_data_df.shape[0]*percent)]\n",
    "valid_data_df = valid_data_df[:int(valid_data_df.shape[0]*percent)]\n",
    "test_data_df = test_data_df[:int(test_data_df.shape[0]*percent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "train_idx_path = basedir+ \"/train_list.txt\"\n",
    "valid_idx_path = basedir+ \"/valid_list.txt\"\n",
    "test_idx_path = basedir+ \"/test_list.txt\"\n",
    "\n",
    "\n",
    "col_names = [\"X\", \"y\"]\n",
    "train_data_df = pd.read_csv(train_idx_path, sep=\" \", header=None, names=col_names)\n",
    "train_data_df.y = train_data_df.y-1\n",
    "valid_data_df = pd.read_csv(valid_idx_path, sep=\" \", header=None, names=col_names)\n",
    "valid_data_df.y = valid_data_df.y-1\n",
    "test_data_df = pd.read_csv(test_idx_path, sep=\" \", header=None, names=col_names)\n",
    "test_data_df.y = test_data_df.y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                X   y\n",
       "0  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg  74\n",
       "1  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg  74\n",
       "2  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg  74\n",
       "3  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg  74\n",
       "4  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg  74"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 2)\n",
      "(835, 2)\n",
      "(836, 2)\n",
      "8351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                X   y\n",
       "0  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg  74\n",
       "1  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg  74\n",
       "2  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg  74\n",
       "3  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg  74\n",
       "4  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg  74"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data_df.shape)\n",
    "print(valid_data_df.shape)\n",
    "print(test_data_df.shape)\n",
    "\n",
    "print(train_data_df.shape[0] + valid_data_df.shape[0] + test_data_df.shape[0])\n",
    "sample_df = test_data_df[:5]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and load images\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#definition of data generator\n",
    "def df_data_generator(df, batch_size=32, num_classes=3, shuffle=False, basedir=\".\", transformer=None):    \n",
    "    while True:\n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1)\n",
    "            \n",
    "        X_file_name = df.X.apply(lambda x: basedir+\"/\"+x) \n",
    "        y = np_utils.to_categorical(df.y, num_classes)\n",
    "    # infinitely serve batches\n",
    "        max_range = (1+ df.shape[0]//batch_size)\n",
    "        for i in range(max_range):\n",
    "            if transformer:\n",
    "                yield transformer(X_file_name[i*batch_size : (i+1)*batch_size]).astype('float32'), y[i*batch_size : (i+1)*batch_size]\n",
    "            else:\n",
    "                yield X_file_name[i*batch_size : (i+1)*batch_size], y[i*batch_size : (i+1)*batch_size]\n",
    "                \n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import keras.applications.mobilenet as mobilenet\n",
    "def transformer(x):\n",
    "    return mobilenet.preprocess_input(paths_to_tensor(x))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## test code\n",
    "test_gen = df_data_generator(sample_df, num_classes=133)\n",
    "X1, _ = next(test_gen)\n",
    "X2, _ =next(test_gen)\n",
    "print(np.hstack((X1, X2)))\n",
    "\n",
    "filename = basedir+\"/test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg\"\n",
    "print(filename)\n",
    "res = transformer([filename])\n",
    "print(res.shape)\n",
    "test_gen = df_data_generator(sample_df, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "X3, y3 =next(test_gen)\n",
    "print(X3.shape)\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_train_name = 'bottleneck_features_mobilenet_train'\n",
    "bnf_valid_name = 'bottleneck_features_mobilenet_valid'\n",
    "bnf_test_name = 'bottleneck_features_mobilenet_test' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def bcolz_prediction_writer(gen, steps, model, dirname ):\n",
    "    X = None; y = None\n",
    "    data_dir = dirname + \"_data.bclz\"\n",
    "    label_dir = dirname + \"_labels.bclz\"\n",
    "    for i in range(steps):\n",
    "        X_batch, y_batch = next(gen)\n",
    "        X_out = model.predict(X_batch)\n",
    "        if i== 0:\n",
    "            X = bcolz.carray(X_out, rootdir=data_dir, mode='w')\n",
    "            y = bcolz.carray(y_batch, rootdir=label_dir, mode='w') \n",
    "        else:\n",
    "            X.append(X_out)\n",
    "            y.append(y_batch)\n",
    "    X.flush()\n",
    "    y.flush()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 12.44444465637207 seconds to calculate bnf_valid_data\n",
      "Took 11.485620260238647 seconds to calculate bnf_test_data\n",
      "Took 96.61987161636353 seconds to calculate bottleneck_features_mobilenet_train\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "import time\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "batch_size=32\n",
    "train_gen = df_data_generator(train_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "valid_gen = df_data_generator(valid_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "test_gen = df_data_generator(test_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "\n",
    "\n",
    "\n",
    "mobilenet_feature_ext = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "mobilenet_feature_ext._make_predict_function()\n",
    "\n",
    "s= time.time()\n",
    "!rm -rf 'bottleneck_features_mobilenet_valid*bclz'\n",
    "bnf_valid_data,  bnf_valid_labels = bcolz_prediction_writer(gen=valid_gen, \n",
    "                        steps=(1+(valid_data_df.shape[0]//batch_size)),\n",
    "                        model=mobilenet_feature_ext,\n",
    "                        dirname=bnf_valid_name)\n",
    "print(\"Took {} seconds to calculate bnf_valid_data\".format(time.time()-s))\n",
    "\n",
    "s= time.time()\n",
    "!rm -rf 'bottleneck_features_mobilenet_test*bclz'\n",
    "bnf_test_data,  bnf_test_labels = bcolz_prediction_writer(gen=test_gen, \n",
    "                        steps=(1+(test_data_df.shape[0]//batch_size)),\n",
    "                        model=mobilenet_feature_ext,\n",
    "                        dirname=bnf_test_name)\n",
    "print(\"Took {} seconds to calculate bnf_test_data\".format(time.time()-s))\n",
    "\n",
    "s= time.time()\n",
    "!rm -rf 'bottleneck_features_mobilenet_train*bclz'\n",
    "bnf_train_data,  bnf_train_labels = bcolz_prediction_writer(gen=train_gen, \n",
    "                        steps=(1+(train_data_df.shape[0]//batch_size)),\n",
    "                        model=mobilenet_feature_ext,\n",
    "                        dirname=bnf_train_name)\n",
    "print(\"Took {} seconds to calculate bottleneck_features_mobilenet_train\".format(time.time()-s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 7, 7, 1024)\n",
      "(836, 7, 7, 1024)\n",
      "(6680, 7, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(bnf_valid_data.shape)\n",
    "print(bnf_test_data.shape)\n",
    "print(bnf_train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 133)\n",
      "(836, 133)\n",
      "(6680, 133)\n"
     ]
    }
   ],
   "source": [
    "print(bnf_valid_labels.shape)\n",
    "print(bnf_test_labels.shape)\n",
    "print(bnf_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 7, 7, 1024)\n",
      "(836, 7, 7, 1024)\n",
      "(6680, 7, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "bnf_valid_data = bcolz.carray(rootdir='bottleneck_features_mobilenet_valid_data.bclz', mode='r')\n",
    "bnf_test_data = bcolz.carray(rootdir='bottleneck_features_mobilenet_test_data.bclz', mode='r')\n",
    "bnf_train_data = bcolz.carray(rootdir='bottleneck_features_mobilenet_train_data.bclz', mode='r')\n",
    "\n",
    "print(bnf_valid_data.shape)\n",
    "print(bnf_test_data.shape)\n",
    "print(bnf_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835, 133)\n",
      "(836, 133)\n",
      "(6680, 133)\n"
     ]
    }
   ],
   "source": [
    "bnf_valid_labels = bcolz.carray(rootdir='bottleneck_features_mobilenet_valid_labels.bclz', mode='r')\n",
    "bnf_test_labels = bcolz.carray(rootdir='bottleneck_features_mobilenet_test_labels.bclz', mode='r')\n",
    "bnf_train_labels = bcolz.carray(rootdir='bottleneck_features_mobilenet_train_labels.bclz', mode='r')\n",
    "\n",
    "print(bnf_valid_labels.shape)\n",
    "print(bnf_test_labels.shape)\n",
    "print(bnf_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnf_data_generator(bnf_data, bnf_labels, batch_size=32):\n",
    "    while True:\n",
    "        max_range = (1 + bnf_data.shape[0]//batch_size)\n",
    "        for i in range(max_range):\n",
    "            yield bnf_data[i*batch_size : (i+1)*batch_size], bnf_labels[i*batch_size : (i+1)*batch_size]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a generator of loaded data\n",
    "batch_size = 256\n",
    "train_gen_fex =bnf_data_generator(bnf_train_data, bnf_train_labels, batch_size=batch_size)\n",
    "valid_gen_fex =bnf_data_generator(bnf_valid_data, bnf_valid_labels, batch_size=batch_size)\n",
    "test_gen_fex = bnf_data_generator(bnf_test_data, bnf_test_labels, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 593,029\n",
      "Trainable params: 593,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "\n",
    "top_model = Sequential()\n",
    "#model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=(7, 7, 1024)))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 5.8511 - acc: 1.5024e-04- ETA: 1s - loss: 6.3756 Epoch 00001: val_loss improved from inf to 4.82630, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 124ms/step - loss: 5.8226 - acc: 1.4486e-04 - val_loss: 4.8263 - val_acc: 0.0551\n",
      "Epoch 2/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 4.8300 - acc: 0.0349Epoch 00002: val_loss improved from 4.82630 to 4.67341, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 4.8337 - acc: 0.0336 - val_loss: 4.6734 - val_acc: 0.0862\n",
      "Epoch 3/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 4.6965 - acc: 0.0601Epoch 00003: val_loss improved from 4.67341 to 4.29803, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 4.6861 - acc: 0.0594 - val_loss: 4.2980 - val_acc: 0.1150\n",
      "Epoch 4/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 4.3582 - acc: 0.0798Epoch 00004: val_loss improved from 4.29803 to 3.69550, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 4.2977 - acc: 0.0963 - val_loss: 3.6955 - val_acc: 0.2335\n",
      "Epoch 5/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 3.8563 - acc: 0.1217Epoch 00005: val_loss improved from 3.69550 to 3.05145, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 3.7658 - acc: 0.1502 - val_loss: 3.0514 - val_acc: 0.3078\n",
      "Epoch 6/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 3.2995 - acc: 0.1759Epoch 00006: val_loss improved from 3.05145 to 2.51612, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 3.1970 - acc: 0.2055 - val_loss: 2.5161 - val_acc: 0.4168\n",
      "Epoch 7/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.8449 - acc: 0.2486Epoch 00007: val_loss improved from 2.51612 to 2.09763, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 2.7505 - acc: 0.2756 - val_loss: 2.0976 - val_acc: 0.5114\n",
      "Epoch 8/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.4509 - acc: 0.3332Epoch 00008: val_loss improved from 2.09763 to 1.74738, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 2.3831 - acc: 0.3541 - val_loss: 1.7474 - val_acc: 0.5784\n",
      "Epoch 9/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.1744 - acc: 0.3980Epoch 00009: val_loss improved from 1.74738 to 1.51051, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 2.1145 - acc: 0.4181 - val_loss: 1.5105 - val_acc: 0.6299\n",
      "Epoch 10/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.8982 - acc: 0.4641Epoch 00010: val_loss improved from 1.51051 to 1.31916, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 1.8408 - acc: 0.4833 - val_loss: 1.3192 - val_acc: 0.6635\n",
      "Epoch 11/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.7015 - acc: 0.5101Epoch 00011: val_loss improved from 1.31916 to 1.18525, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 1.6476 - acc: 0.5276 - val_loss: 1.1852 - val_acc: 0.7042\n",
      "Epoch 12/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.5010 - acc: 0.5654Epoch 00012: val_loss improved from 1.18525 to 1.07279, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 1.4564 - acc: 0.5794 - val_loss: 1.0728 - val_acc: 0.7222\n",
      "Epoch 13/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.3765 - acc: 0.5928Epoch 00013: val_loss improved from 1.07279 to 0.99178, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 1.3322 - acc: 0.6074 - val_loss: 0.9918 - val_acc: 0.7425\n",
      "Epoch 14/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.2397 - acc: 0.6340Epoch 00014: val_loss improved from 0.99178 to 0.90812, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 1.2084 - acc: 0.6441 - val_loss: 0.9081 - val_acc: 0.7545\n",
      "Epoch 15/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.1551 - acc: 0.6489Epoch 00015: val_loss improved from 0.90812 to 0.86279, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 1.1199 - acc: 0.6615 - val_loss: 0.8628 - val_acc: 0.7605\n",
      "Epoch 16/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.0699 - acc: 0.6713Epoch 00016: val_loss improved from 0.86279 to 0.80744, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 1.0363 - acc: 0.6831 - val_loss: 0.8074 - val_acc: 0.7689\n",
      "Epoch 17/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.9784 - acc: 0.6985Epoch 00017: val_loss improved from 0.80744 to 0.77052, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 0.9513 - acc: 0.7078 - val_loss: 0.7705 - val_acc: 0.7808\n",
      "Epoch 18/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.9297 - acc: 0.7118Epoch 00018: val_loss improved from 0.77052 to 0.74502, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 0.9033 - acc: 0.7207 - val_loss: 0.7450 - val_acc: 0.7784\n",
      "Epoch 19/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.8796 - acc: 0.7348Epoch 00019: val_loss improved from 0.74502 to 0.71761, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 0.8561 - acc: 0.7413 - val_loss: 0.7176 - val_acc: 0.7928\n",
      "Epoch 20/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.8279 - acc: 0.7423Epoch 00020: val_loss improved from 0.71761 to 0.68753, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 0.8010 - acc: 0.7516 - val_loss: 0.6875 - val_acc: 0.8048\n",
      "Epoch 21/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7650 - acc: 0.7631Epoch 00021: val_loss improved from 0.68753 to 0.67364, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 0.7408 - acc: 0.7716 - val_loss: 0.6736 - val_acc: 0.8036\n",
      "Epoch 22/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7431 - acc: 0.7647Epoch 00022: val_loss improved from 0.67364 to 0.64935, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 0.7191 - acc: 0.7732 - val_loss: 0.6494 - val_acc: 0.8048\n",
      "Epoch 23/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6865 - acc: 0.7888Epoch 00023: val_loss improved from 0.64935 to 0.63866, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 0.6669 - acc: 0.7948 - val_loss: 0.6387 - val_acc: 0.8156\n",
      "Epoch 24/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6584 - acc: 0.7964Epoch 00024: val_loss improved from 0.63866 to 0.62308, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 0.6402 - acc: 0.8022 - val_loss: 0.6231 - val_acc: 0.8204\n",
      "Epoch 25/25\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6211 - acc: 0.8044Epoch 00025: val_loss improved from 0.62308 to 0.60895, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 0.6004 - acc: 0.8114 - val_loss: 0.6089 - val_acc: 0.8216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc3203addd8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.topmodel.mobilenet.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "top_model.fit_generator(train_gen_fex,\n",
    "          steps_per_epoch= (1 + (train_data_df.shape[0]// batch_size)),\n",
    "          epochs=25,\n",
    "          validation_data=valid_gen_fex,\n",
    "          validation_steps= (1 + (valid_data_df.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_from_gen(gen, steps, model, dirname ):\n",
    "    y_true = None; y_pred = None\n",
    "    yt_dir = dirname + \"_y_true.bclz\"\n",
    "    yp_dir = dirname + \"_y_pred.bclz\"\n",
    "    for i in range(steps):\n",
    "        X_batch, y_batch = next(gen)\n",
    "        y_out = model.predict(X_batch)\n",
    "        if i== 0:\n",
    "            y_true = bcolz.carray(y_batch, rootdir=yt_dir, mode='w')\n",
    "            y_pred = bcolz.carray(y_out, rootdir=yp_dir, mode='w') \n",
    "        else:\n",
    "            y_true.append(y_batch)\n",
    "            y_pred.append(y_out)\n",
    "    y_true.flush()\n",
    "    y_pred.flush()\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = prediction_from_gen(gen=test_gen_fex,\n",
    "                                     steps=(1 + (test_data_df.shape[0] // batch_size)),\n",
    "                                     model=top_model,\n",
    "                                     dirname=\"bottleneck_features_mobilenet_test\"\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(836, 133)\n",
      "(836, 133)\n"
     ]
    }
   ],
   "source": [
    "print(y_true.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 80.6220%\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.argmax(y_pred, axis=1)==np.argmax(y_true, axis=1))/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "top_model.fit(train_data[:250], train_labels[:250],\n",
    "          epochs=25,\n",
    "          batch_size=64,\n",
    "          validation_data=(valid_data[:150], valid_labels[:150]),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for use without streaming\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "top_model.fit(train_data, train_labels,\n",
    "          epochs=25,\n",
    "          batch_size=64,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.topmodel.mobilenet.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "top_model.fit_generator(train_gen_fex,\n",
    "          steps_per_epoch= (train_data_df.shape[0]// batch_size),\n",
    "          epochs=25,\n",
    "          validation_data=valid_gen_fex,\n",
    "          validation_steps= (valid_data_df.shape[0] // batch_size),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 133)               593029    \n",
      "=================================================================\n",
      "Total params: 3,821,893\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,821,893\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine tune on full model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "mobilenet_model = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# CREATE AN \"REAL\" MODEL FROM Mobilenet\n",
    "# BY COPYING ALL THE LAYERS OF Mobilenet\n",
    "model = Sequential()\n",
    "for l in mobilenet_model.layers:\n",
    "    model.add(l)\n",
    "\n",
    "\n",
    "# CONCATENATE THE TWO MODELS\n",
    "model.add(top_model)\n",
    "\n",
    "# LOCK THE TOP CONV LAYERS\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# COMPILE THE MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/27 [===========================>..] - ETA: 2s - loss: 1.8623 - acc: 0.4865Epoch 00001: val_loss improved from inf to 0.63417, saving model to saved_models/weights.best.fullmodel.mobilenet.hdf5\n",
      "27/27 [==============================] - 87s 3s/step - loss: 2.1309 - acc: 0.4690 - val_loss: 0.6342 - val_acc: 0.8120\n",
      "Epoch 2/2\n",
      "25/27 [==========================>...] - ETA: 4s - loss: 1.8657 - acc: 0.4852"
     ]
    }
   ],
   "source": [
    "# load train, test, and validation datasets\n",
    "batch_size=256\n",
    "train_gen = df_data_generator(train_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "valid_gen = df_data_generator(valid_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "test_gen = df_data_generator(test_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.fullmodel.mobilenet.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch= (1+ train_data_df.shape[0]// batch_size),\n",
    "          epochs=2,\n",
    "          validation_data=valid_gen,\n",
    "          validation_steps= (1+ valid_data_df.shape[0] // batch_size),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true, y_pred = prediction_from_gen(gen=test_gen,\n",
    "                                     steps=(1 + (test_data_df.shape[0] // batch_size)),\n",
    "                                     model=model,\n",
    "                                     dirname=\"mobilenet_test\"\n",
    "                                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dog-project]",
   "language": "python",
   "name": "conda-env-dog-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
