{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tutysara/anaconda2/envs/dog-project/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import importlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Display progress logs on stdout\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG,\n",
    "#                   format='%(asctime)s %(levelname)s %(message)s')\n",
    "#logger = logging.getLogger()\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 75)\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from '/home/tutysara/src/myprojects/mlnd-capstone/util.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bcolzutils\n",
    "from bcolzutils import *\n",
    "importlib.reload(bcolzutils) \n",
    "\n",
    "\n",
    "import util\n",
    "from util import *\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make the csv files for dog project\n",
    "cd dogImages\n",
    "for filename in $(find train|grep .jpg); do\n",
    "    label=$(echo $filename| cut -d'/' -f 2)\n",
    "    label_num=$(echo $label| cut -d'.' -f 1)\n",
    "    echo \"$filename $label_num\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "basedir=\"/media/hdd/datastore/t4sa\"\n",
    "train_idx_path = basedir+ \"/b-t4sa_train.txt\"\n",
    "valid_idx_path = basedir+ \"/b-t4sa_val.txt\"\n",
    "test_idx_path = basedir+ \"/b-t4sa_test.txt\"\n",
    "num_classes = 3\n",
    "\n",
    "col_names = [\"X\", \"y\"]\n",
    "percent = 0.005\n",
    "train_data_df = pd.read_csv(train_idx_path, sep=\" \", header=None, names=col_names)\n",
    "valid_data_df = pd.read_csv(valid_idx_path, sep=\" \", header=None, names=col_names)\n",
    "test_data_df = pd.read_csv(test_idx_path, sep=\" \", header=None, names=col_names)\n",
    "\n",
    "train_data_df = train_data_df[:int(train_data_df.shape[0]*percent)]\n",
    "valid_data_df = valid_data_df[:int(valid_data_df.shape[0]*percent)]\n",
    "test_data_df = test_data_df[:int(test_data_df.shape[0]*percent)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "train_idx_path = basedir+ \"/train_list.txt\"\n",
    "valid_idx_path = basedir+ \"/valid_list.txt\"\n",
    "test_idx_path = basedir+ \"/test_list.txt\"\n",
    "num_classes = 133    \n",
    "\n",
    "col_names = [\"X\", \"y\"]\n",
    "percent = 0.3\n",
    "train_data_df = pd.read_csv(train_idx_path, sep=\" \", header=None, names=col_names)\n",
    "valid_data_df = pd.read_csv(valid_idx_path, sep=\" \", header=None, names=col_names)\n",
    "test_data_df = pd.read_csv(test_idx_path, sep=\" \", header=None, names=col_names)\n",
    "\n",
    "train_data_df = train_data_df[:int(train_data_df.shape[0]*percent)]\n",
    "valid_data_df = valid_data_df[:int(valid_data_df.shape[0]*percent)]\n",
    "test_data_df = test_data_df[:int(test_data_df.shape[0]*percent)]\n",
    "\n",
    "train_data_df.y = train_data_df.y-1\n",
    "valid_data_df.y = valid_data_df.y-1\n",
    "test_data_df.y = test_data_df.y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/76878/768781748033335296-1.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/80174/801747152955326465-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/76899/768993807845163008-3.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/80162/801624637314629634-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/78083/780835980597194753-1.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     X  y\n",
       "0  data/76878/768781748033335296-1.jpg  2\n",
       "1  data/80174/801747152955326465-1.jpg  0\n",
       "2  data/76899/768993807845163008-3.jpg  2\n",
       "3  data/80162/801624637314629634-1.jpg  0\n",
       "4  data/78083/780835980597194753-1.jpg  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1842, 2)\n",
      "(255, 2)\n",
      "(255, 2)\n",
      "2352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/76878/768781748033335296-1.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/80174/801747152955326465-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/76899/768993807845163008-3.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/80162/801624637314629634-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/78083/780835980597194753-1.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     X  y\n",
       "0  data/76878/768781748033335296-1.jpg  2\n",
       "1  data/80174/801747152955326465-1.jpg  0\n",
       "2  data/76899/768993807845163008-3.jpg  2\n",
       "3  data/80162/801624637314629634-1.jpg  0\n",
       "4  data/78083/780835980597194753-1.jpg  2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data_df.shape)\n",
    "print(valid_data_df.shape)\n",
    "print(test_data_df.shape)\n",
    "\n",
    "print(train_data_df.shape[0] + valid_data_df.shape[0] + test_data_df.shape[0])\n",
    "sample_df = test_data_df[:5]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/28800526...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/33547480...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/27176682...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/10096570...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/13247920...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            X  \\\n",
       "0  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/28800526...   \n",
       "1  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/33547480...   \n",
       "2  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/27176682...   \n",
       "3  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/10096570...   \n",
       "4  /home/tutysara/src/myprojects/senti/dataset/Agg_AMT_Candidates/13247920...   \n",
       "\n",
       "   y  \n",
       "0  0  \n",
       "1  1  \n",
       "2  1  \n",
       "3  1  \n",
       "4  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load TTD\n",
    "ttd_basedir=\"/home/tutysara/src/myprojects/senti/dataset\"\n",
    "ttd_data_idx_path = ttd_basedir+ \"/twitter_five_agrees.txt\"\n",
    "col_names = [\"X\", \"y\"]\n",
    "ttd_data_df = pd.read_csv(ttd_data_idx_path, sep=\" \", header=None, names=col_names)\n",
    "ttd_data_df.X = ttd_data_df.X.apply(lambda x: ttd_basedir+\"/Agg_AMT_Candidates/\"+x)\n",
    "print(ttd_data_df.shape)\n",
    "ttd_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_valid_name = 'bottleneck_features_mobilenet_valid'\n",
    "bnf_test_name = 'bottleneck_features_mobilenet_test' \n",
    "bnf_train_name = 'bottleneck_features_mobilenet_train'\n",
    "\n",
    "valid_name = basedir + '/valid_data'\n",
    "test_name = basedir + '/test_data'\n",
    "train_name = basedir +'/train_data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 224, 224, 3)\n",
      "(51000, 224, 224, 3)\n",
      "(368586, 224, 224, 3)\n",
      "(51000, 3)\n",
      "(51000, 3)\n",
      "(368586, 3)\n"
     ]
    }
   ],
   "source": [
    "# read from disk and check size\n",
    "valid_data = bcolz.carray(rootdir= valid_name+'_data.bclz', mode='r')\n",
    "test_data = bcolz.carray(rootdir= test_name + '_data.bclz', mode='r')\n",
    "train_data = bcolz.carray(rootdir= train_name+ '_data.bclz', mode='r')\n",
    "\n",
    "\n",
    "valid_labels = bcolz.carray(rootdir= valid_name+'_labels.bclz', mode='r')\n",
    "test_labels = bcolz.carray(rootdir= test_name + '_labels.bclz', mode='r')\n",
    "train_labels = bcolz.carray(rootdir= train_name+ '_labels.bclz', mode='r')\n",
    "\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.shape)\n",
    "\n",
    "print(valid_labels.shape)\n",
    "print(test_labels.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make a generator of loaded data\n",
    "batch_size = 256\n",
    "valid_data_gen = bcolz_data_generator(valid_data, valid_labels, batch_size=batch_size, progress=True)\n",
    "test_data_gen = bcolz_data_generator(test_data, test_labels, batch_size=batch_size, progress=True)\n",
    "train_data_gen = bcolz_data_generator(train_data, train_labels, batch_size=batch_size, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.39 seconds to calculate bnf_valid_data\n",
      "Took 1.23 seconds to calculate bnf_test_data\n",
      "bcolz.gen Iteration 0/8 took 1.08s\n",
      "bcolz.gen Iteration 1/8 took 1.07s\n",
      "bcolz.gen Iteration 2/8 took 1.09s\n",
      "bcolz.gen Iteration 3/8 took 1.09s\n",
      "bcolz.gen Iteration 4/8 took 1.10s\n",
      "bcolz.gen Iteration 5/8 took 1.08s\n",
      "bcolz.gen Iteration 6/8 took 1.09s\n",
      "Took 7.81 seconds to calculate bottleneck_features_mobilenet_train\n"
     ]
    }
   ],
   "source": [
    "## Transform data and save it in bottleneck feacture format\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input as mobilenet_preprocess_input\n",
    "import time\n",
    "\n",
    "mobilenet_feature_ext = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "mobilenet_feature_ext._make_predict_function()\n",
    "\n",
    "s= time.time()\n",
    "remove_bcolz_dir(bnf_valid_name)\n",
    "bnf_valid_data,  bnf_valid_labels = bcolz_prediction_writer(gen=valid_data_gen, \n",
    "                        steps=(1+(valid_data_df.shape[0]//batch_size)),\n",
    "                        model=mobilenet_feature_ext,\n",
    "                        preprocess= mobilenet_preprocess_input,\n",
    "                        dirname=bnf_valid_name)\n",
    "print(\"Took {:.2f} seconds to calculate bnf_valid_data\".format(time.time()-s))\n",
    "\n",
    "s= time.time()\n",
    "remove_bcolz_dir(bnf_test_name)\n",
    "!rm -rf 'bottleneck_features_mobilenet_test*bclz'\n",
    "bnf_test_data,  bnf_test_labels = bcolz_prediction_writer(gen=test_data_gen, \n",
    "                        steps=(1+(test_data_df.shape[0]//batch_size)),\n",
    "                        model=mobilenet_feature_ext,\n",
    "                        preprocess= mobilenet_preprocess_input,\n",
    "                        dirname=bnf_test_name)\n",
    "print(\"Took {:.2f} seconds to calculate bnf_test_data\".format(time.time()-s))\n",
    "\n",
    "s= time.time()\n",
    "remove_bcolz_dir(bnf_train_name)\n",
    "bnf_train_data,  bnf_train_labels = bcolz_prediction_writer(gen=train_data_gen, \n",
    "                        steps=(1+(train_data_df.shape[0]//batch_size)),\n",
    "                        model=mobilenet_feature_ext,\n",
    "                        preprocess= mobilenet_preprocess_input,\n",
    "                        dirname=bnf_train_name)\n",
    "print(\"Took {:.2f} seconds to calculate bottleneck_features_mobilenet_train\".format(time.time()-s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 7, 7, 1024)\n",
      "(255, 7, 7, 1024)\n",
      "(1842, 7, 7, 1024)\n",
      "(255, 3)\n",
      "(255, 3)\n",
      "(1842, 3)\n"
     ]
    }
   ],
   "source": [
    "print(bnf_valid_data.shape)\n",
    "print(bnf_test_data.shape)\n",
    "print(bnf_train_data.shape)\n",
    "\n",
    "print(bnf_valid_labels.shape)\n",
    "print(bnf_test_labels.shape)\n",
    "print(bnf_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 7, 7, 1024)\n",
      "(255, 7, 7, 1024)\n",
      "(1842, 7, 7, 1024)\n",
      "(255, 3)\n",
      "(255, 3)\n",
      "(1842, 3)\n"
     ]
    }
   ],
   "source": [
    "## Read it back from disk and check size\n",
    "bnf_valid_data = bcolz.carray(rootdir=f'{bnf_valid_name}_data.bclz', mode='r')\n",
    "bnf_test_data = bcolz.carray(rootdir=f'{bnf_test_name}_data.bclz', mode='r')\n",
    "bnf_train_data = bcolz.carray(rootdir=f'{bnf_train_name}_data.bclz', mode='r')\n",
    "\n",
    "bnf_valid_labels = bcolz.carray(rootdir=f'{bnf_valid_name}_labels.bclz', mode='r')\n",
    "bnf_test_labels = bcolz.carray(rootdir=f'{bnf_test_name}_labels.bclz', mode='r')\n",
    "bnf_train_labels = bcolz.carray(rootdir=f'{bnf_train_name}_labels.bclz', mode='r')\n",
    "\n",
    "print(bnf_valid_data.shape)\n",
    "print(bnf_test_data.shape)\n",
    "print(bnf_train_data.shape)\n",
    "\n",
    "\n",
    "print(bnf_valid_labels.shape)\n",
    "print(bnf_test_labels.shape)\n",
    "print(bnf_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make a generator of loaded data\n",
    "batch_size = 256\n",
    "bnf_train_gen =bcolz_data_generator(bnf_train_data, bnf_train_labels, batch_size=batch_size)\n",
    "bnf_valid_gen =bcolz_data_generator(bnf_valid_data, bnf_valid_labels, batch_size=batch_size)\n",
    "bnf_test_gen =bcolz_data_generator(bnf_test_data, bnf_test_labels, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "\n",
    "top_model = Sequential()\n",
    "#model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=(7, 7, 1024)))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 3)           3075      \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 3)           0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,075\n",
      "Trainable params: 3,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Reshape\n",
    "from keras import regularizers\n",
    "\n",
    "alpha = 1\n",
    "dropout=1e-3\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape = (int(1024 * alpha), 1, 1)\n",
    "else:\n",
    "    shape = (1, 1, int(1024 * alpha))\n",
    "\n",
    "classes = num_classes\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(GlobalAveragePooling2D(input_shape=(7, 7, 1024)))\n",
    "top_model.add(Reshape(shape, name='reshape_1'))\n",
    "top_model.add(Dropout(dropout, name='dropout'))\n",
    "top_model.add(Conv2D(classes, (1, 1),\n",
    "           padding='same', name='conv_preds'))\n",
    "top_model.add(Activation('softmax', name='act_softmax'))\n",
    "top_model.add(Reshape((classes,), name='reshape_2'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.4400 - acc: 0.3125Epoch 00001: val_loss improved from inf to 1.36066, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.4170 - acc: 0.3202 - val_loss: 1.3607 - val_acc: 0.2863\n",
      "Epoch 2/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.3202 - acc: 0.3560Epoch 00002: val_loss improved from 1.36066 to 1.31994, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 1.3001 - acc: 0.3725 - val_loss: 1.3199 - val_acc: 0.3137\n",
      "Epoch 3/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.2208 - acc: 0.3800Epoch 00003: val_loss improved from 1.31994 to 1.24899, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.1965 - acc: 0.4028 - val_loss: 1.2490 - val_acc: 0.3725\n",
      "Epoch 4/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.1808 - acc: 0.4090Epoch 00004: val_loss improved from 1.24899 to 1.24646, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.1523 - acc: 0.4331 - val_loss: 1.2465 - val_acc: 0.3608\n",
      "Epoch 5/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.1367 - acc: 0.4185Epoch 00005: val_loss improved from 1.24646 to 1.19514, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.1039 - acc: 0.4415 - val_loss: 1.1951 - val_acc: 0.3725\n",
      "Epoch 6/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.1055 - acc: 0.4297Epoch 00006: val_loss improved from 1.19514 to 1.18831, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.0688 - acc: 0.4583 - val_loss: 1.1883 - val_acc: 0.3686\n",
      "Epoch 7/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0764 - acc: 0.4554Epoch 00007: val_loss improved from 1.18831 to 1.16769, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.0343 - acc: 0.4924 - val_loss: 1.1677 - val_acc: 0.3882\n",
      "Epoch 8/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0564 - acc: 0.4665Epoch 00008: val_loss improved from 1.16769 to 1.16033, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.0111 - acc: 0.5069 - val_loss: 1.1603 - val_acc: 0.4000\n",
      "Epoch 9/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0362 - acc: 0.4833Epoch 00009: val_loss improved from 1.16033 to 1.15649, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.9870 - acc: 0.5263 - val_loss: 1.1565 - val_acc: 0.4157\n",
      "Epoch 10/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0165 - acc: 0.5022Epoch 00010: val_loss improved from 1.15649 to 1.15162, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9648 - acc: 0.5522 - val_loss: 1.1516 - val_acc: 0.4039\n",
      "Epoch 11/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0013 - acc: 0.5140Epoch 00011: val_loss improved from 1.15162 to 1.14998, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.9477 - acc: 0.5649 - val_loss: 1.1500 - val_acc: 0.4118\n",
      "Epoch 12/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9850 - acc: 0.5290Epoch 00012: val_loss improved from 1.14998 to 1.14725, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9298 - acc: 0.5782 - val_loss: 1.1473 - val_acc: 0.4235\n",
      "Epoch 13/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9703 - acc: 0.5379Epoch 00013: val_loss improved from 1.14725 to 1.14605, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9140 - acc: 0.5884 - val_loss: 1.1461 - val_acc: 0.4196\n",
      "Epoch 14/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9567 - acc: 0.5552Epoch 00014: val_loss did not improve\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.8994 - acc: 0.6060 - val_loss: 1.1462 - val_acc: 0.4196\n",
      "Epoch 15/15\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9429 - acc: 0.5619Epoch 00015: val_loss improved from 1.14605 to 1.14565, saving model to saved_models/weights.best.topmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.8845 - acc: 0.6097 - val_loss: 1.1457 - val_acc: 0.4235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b71775518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.topmodel.mobilenet.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "top_model.fit_generator(bnf_train_gen,\n",
    "          steps_per_epoch= (1 + (bnf_train_data.shape[0]// batch_size)),\n",
    "          epochs=15,\n",
    "          validation_data=bnf_valid_gen,\n",
    "          validation_steps= (1 + (bnf_valid_data.shape[0] // batch_size)),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = prediction_from_gen(gen=bnf_test_gen,\n",
    "                                     steps=(1 + (test_data_df.shape[0] // batch_size)),\n",
    "                                     model=top_model,\n",
    "                                     dirname=\"bottleneck_features_mobilenet_test\")\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 3)\n",
      "(255, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_true.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 45.0980%\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.argmax(y_pred, axis=1)==np.argmax(y_true, axis=1))/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report test accuracy on TTD\n",
    "ttd_X1 = ttd_data_df.X.as_matrix()\n",
    "ttd_X2 = mobilenet_preprocess_input(paths_to_tensor(ttd_X1))\n",
    "ttd_X = mobilenet_feature_ext.predict(ttd_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttd_y_pred = top_model.predict(ttd_X)\n",
    "ttd_y_pred_two_classes=ttd_y_pred[:,[0,2]]\n",
    "ttd_y_true = ttd_data_df.y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(882, 7, 7, 1024)\n",
      "(882, 3)\n",
      "(882,)\n"
     ]
    }
   ],
   "source": [
    "print(ttd_X.shape)\n",
    "print(ttd_y_pred.shape)\n",
    "print(ttd_y_true.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTD Test accuracy: 58.6168%\n"
     ]
    }
   ],
   "source": [
    "ttd_test_accuracy = 100*np.sum(np.argmax(ttd_y_pred_two_classes, axis=1)==ttd_y_true)/len(ttd_y_true)\n",
    "print('TTD Test accuracy: %.4f%%' % ttd_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,231,939\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine tune on full model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "mobilenet_model = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# CREATE AN \"REAL\" MODEL FROM Mobilenet\n",
    "# BY COPYING ALL THE LAYERS OF Mobilenet\n",
    "model = Sequential()\n",
    "for l in mobilenet_model.layers:\n",
    "    model.add(l)\n",
    "\n",
    "\n",
    "# CONCATENATE THE TWO MODELS\n",
    "model.add(top_model)\n",
    "\n",
    "# LOCK THE TOP CONV LAYERS\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# COMPILE THE MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0137 - acc: 0.5022Epoch 00001: val_loss improved from inf to 1.20295, saving model to saved_models/weights.best.fullmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.9668 - acc: 0.5408 - val_loss: 1.2030 - val_acc: 0.4039\n",
      "Epoch 2/2\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0142 - acc: 0.5084Epoch 00002: val_loss improved from 1.20295 to 1.19752, saving model to saved_models/weights.best.fullmodel.mobilenet.hdf5\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.9680 - acc: 0.5439 - val_loss: 1.1975 - val_acc: 0.4118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6aacb182e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train, test, and validation datasets\n",
    "batch_size = 256\n",
    "valid_data_gen = bcolz_data_generator(valid_data, valid_labels, batch_size=batch_size, progress=False)\n",
    "test_data_gen = bcolz_data_generator(test_data, test_labels, batch_size=batch_size, progress=False)\n",
    "train_data_gen = bcolz_data_generator(train_data, train_labels, batch_size=batch_size, progress=False)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.fullmodel.mobilenet.hdf5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "model.fit_generator(train_data_gen,\n",
    "          steps_per_epoch= (1+ train_data_df.shape[0]// batch_size),\n",
    "          epochs=2,\n",
    "          validation_data=valid_data_gen,\n",
    "          validation_steps= (1+ valid_data_df.shape[0] // batch_size),\n",
    "          callbacks=[early_stopping, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = prediction_from_gen(gen=test_data_gen,\n",
    "                                     steps=(1 + (test_data_df.shape[0] // batch_size)),\n",
    "                                     model=model,\n",
    "                                     dirname=\"mobilenet_test\")\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 42.3529%\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.argmax(y_pred, axis=1)==np.argmax(y_true, axis=1))/len(y_true)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report test accuracy on TTD\n",
    "ttd_X1 = ttd_data_df.X.as_matrix()\n",
    "ttd_X2 = mobilenet_preprocess_input(paths_to_tensor(ttd_X1))\n",
    "ttd_y_pred = model.predict(ttd_X2)\n",
    "    \n",
    "ttd_y_pred_two_classes=ttd_y_pred[:,[0,2]]\n",
    "ttd_y_true = ttd_data_df.y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTD Test accuracy: 34.0136%\n"
     ]
    }
   ],
   "source": [
    "ttd_test_accuracy = 100*np.sum(np.argmax(ttd_y_pred_two_classes, axis=1)==ttd_y_true)/len(ttd_y_true)\n",
    "print('TTD Test accuracy: %.4f%%' % ttd_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
