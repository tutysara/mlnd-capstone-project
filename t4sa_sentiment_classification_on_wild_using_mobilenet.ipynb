{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Display progress logs on stdout\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG,\n",
    "#                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 75)\n",
    "\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make the csv files for dog project\n",
    "cd dogImages\n",
    "for filename in $(find train|grep .jpg); do\n",
    "    label=$(echo $filename| cut -d'/' -f 2)\n",
    "    label_num=$(echo $label| cut -d'.' -f 1)\n",
    "    echo \"$filename $label_num\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "basedir=\"/home/tutysara/src/myprojects/t4sa/data\"\n",
    "train_idx_path = basedir+ \"/b-t4sa_train.txt\"\n",
    "valid_idx_path = basedir+ \"/b-t4sa_val.txt\"\n",
    "test_idx_path = basedir+ \"/b-t4sa_test.txt\"\n",
    "\n",
    "\n",
    "col_names = [\"X\", \"y\"]\n",
    "train_data_df = pd.read_csv(train_idx_path, sep=\" \", header=None, names=col_names)\n",
    "valid_data_df = pd.read_csv(valid_idx_path, sep=\" \", header=None, names=col_names)\n",
    "test_data_df = pd.read_csv(test_idx_path, sep=\" \", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir=\"/home/tutysara/src/myprojects/dog-project/dogImages\"\n",
    "train_idx_path = basedir+ \"/train_list.txt\"\n",
    "valid_idx_path = basedir+ \"/valid_list.txt\"\n",
    "test_idx_path = basedir+ \"/test_list.txt\"\n",
    "\n",
    "\n",
    "col_names = [\"X\", \"y\"]\n",
    "train_data_df = pd.read_csv(train_idx_path, sep=\" \", header=None, names=col_names)\n",
    "train_data_df.y = train_data_df.y-1\n",
    "valid_data_df = pd.read_csv(valid_idx_path, sep=\" \", header=None, names=col_names)\n",
    "valid_data_df.y = valid_data_df.y-1\n",
    "test_data_df = pd.read_csv(test_idx_path, sep=\" \", header=None, names=col_names)\n",
    "test_data_df.y = test_data_df.y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                X   y\n",
       "0  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg  74\n",
       "1  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg  74\n",
       "2  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg  74\n",
       "3  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg  74\n",
       "4  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg  74"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 2)\n",
      "(835, 2)\n",
      "(836, 2)\n",
      "8351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                X   y\n",
       "0  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg  74\n",
       "1  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05143.jpg  74\n",
       "2  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05164.jpg  74\n",
       "3  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05129.jpg  74\n",
       "4  test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05149.jpg  74"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data_df.shape)\n",
    "print(valid_data_df.shape)\n",
    "print(test_data_df.shape)\n",
    "\n",
    "print(train_data_df.shape[0] + valid_data_df.shape[0] + test_data_df.shape[0])\n",
    "sample_df = test_data_df[:5]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and load images\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#definition of data generator\n",
    "def df_data_generator(df, batch_size=32, num_classes=3, shuffle=False, basedir=\".\", transformer=None):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1)\n",
    "            \n",
    "    X_file_name = df.X.apply(lambda x: basedir+\"/\"+x) \n",
    "    y = np_utils.to_categorical(df.y, num_classes)\n",
    "    # infinitely serve batches\n",
    "    \n",
    "    while True:\n",
    "        max_range = max(1, df.shape[0]//batch_size)\n",
    "        for i in range(max_range):\n",
    "            if transformer:\n",
    "                yield transformer(X_file_name[i*batch_size : (i+1)*batch_size]).astype('float32'), y[i*batch_size : (i+1)*batch_size]\n",
    "            else:\n",
    "                yield X_file_name[i*batch_size : (i+1)*batch_size], y[i*batch_size : (i+1)*batch_size]\n",
    "                \n",
    "\n",
    "import keras.applications.mobilenet as mobilenet\n",
    "\n",
    "def transformer(x):\n",
    "    return mobilenet.preprocess_input(paths_to_tensor(x))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## test code\n",
    "test_gen = df_data_generator(sample_df, num_classes=133)\n",
    "X1, _ = next(test_gen)\n",
    "X2, _ =next(test_gen)\n",
    "print(np.hstack((X1, X2)))\n",
    "\n",
    "filename = basedir+\"/test/075.Glen_of_imaal_terrier/Glen_of_imaal_terrier_05148.jpg\"\n",
    "print(filename)\n",
    "res = transformer([filename])\n",
    "print(res.shape)\n",
    "test_gen = df_data_generator(sample_df, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "X3, y3 =next(test_gen)\n",
    "print(X3.shape)\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, test, and validation datasets\n",
    "train_gen = df_data_generator(train_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "valid_gen = df_data_generator(valid_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n",
    "test_gen = df_data_generator(test_data_df, batch_size=batch_size, transformer=transformer, basedir=basedir, num_classes=133)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_train_name = 'bottleneck_features_mobilenet_train.npy'\n",
    "bnf_valid_name = 'bottleneck_features_mobilenet_valid.npy'\n",
    "bnf_test_name = 'bottleneck_features_mobilenet_test.npy' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "mobilenet_feature_ext = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "bottleneck_features_train = mobilenet_feature_ext.predict_generator(train_gen, steps=(train_data_df.shape[0]//batch_size))\n",
    "np.save(open(bnf_train_name, 'wb'),bottleneck_features_train)\n",
    "\n",
    "bottleneck_features_test = mobilenet_feature_ext.predict_generator(valid_gen, steps=(valid_data_df.shape[0]//batch_size))\n",
    "np.save(open(bnf_valid_name, 'wb'),bottleneck_features_test)\n",
    "\n",
    "bottleneck_features_validation = mobilenet_feature_ext.predict_generator(test_gen, steps=(test_data_df.shape[0]//batch_size))\n",
    "np.save(open(bnf_test_name, 'wb'),bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load convered data back\n",
    "train_data = np.load(open(bnf_train_name, 'rb'))\n",
    "valid_data = np.load(open(bnf_valid_name, 'rb'))\n",
    "test_data = np.load(open(bnf_test_name, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6656, 7, 7, 1024)\n",
      "(832, 7, 7, 1024)\n",
      "(832, 7, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build labels for batch classifier\n",
    "train_labels = np_utils.to_categorical(train_data_df.y[:train_data.shape[0]], num_classes)\n",
    "valid_labels = np_utils.to_categorical(valid_data_df.y[:valid_data.shape[0]], num_classes)\n",
    "test_labels = np_utils.to_categorical(test_data_df.y[:test_data.shape[0]], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6656, 133)\n",
      "(832, 133)\n",
      "(832, 133)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(valid_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fex_data_generator(fex_data, df, batch_size=32, num_classes=3):\n",
    "    # infinitely serve batches \n",
    "    y = np_utils.to_categorical(df.y, num_classes)\n",
    "    while True:\n",
    "        max_range = max(1, fex_data.shape[0]//batch_size)\n",
    "        for i in range(max_range):\n",
    "            yield fex_data[i*batch_size : (i+1)*batch_size], y[i*batch_size : (i+1)*batch_size]\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a generator of loaded data\n",
    "num_classes = 133\n",
    "train_gen_fex =fex_data_generator(train_data, train_data_df, num_classes=num_classes, batch_size=256)\n",
    "valid_gen_fex =fex_data_generator(valid_data, valid_data_df, num_classes=num_classes, batch_size=256)\n",
    "test_gen_fex =fex_data_generator(test_data, test_data_df, num_classes=num_classes, batch_size=256) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## test code\n",
    "Xt, yt = next(test_gen_fex)\n",
    "print(Xt.shape)\n",
    "print(yt.shape)\n",
    "res = np_utils.to_categorical(yt, 133)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 593,029\n",
      "Trainable params: 593,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(GlobalAveragePooling2D(input_shape=(7, 7, 1024)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 150 samples\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2.9428 - acc: 0.4760 - val_loss: 7.5708 - val_acc: 0.1933\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 0s 418us/step - loss: 0.3875 - acc: 0.9160 - val_loss: 10.2812 - val_acc: 0.2333\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 0s 366us/step - loss: 0.0946 - acc: 0.9800 - val_loss: 11.7414 - val_acc: 0.2533\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 0s 360us/step - loss: 0.0505 - acc: 0.9800 - val_loss: 11.9889 - val_acc: 0.2467\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 0s 375us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 12.0134 - val_acc: 0.2533\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865485f240>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "model.fit(train_data[:250], train_labels[:250],\n",
    "          epochs=25,\n",
    "          batch_size=64,\n",
    "          validation_data=(valid_data[:150], valid_labels[:150]),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6656 samples, validate on 832 samples\n",
      "Epoch 1/25\n",
      "6656/6656 [==============================] - 2s 277us/step - loss: 7.9162 - acc: 0.1247 - val_loss: 2.1702 - val_acc: 0.5216\n",
      "Epoch 2/25\n",
      "6656/6656 [==============================] - 2s 270us/step - loss: 1.6049 - acc: 0.5596 - val_loss: 0.9626 - val_acc: 0.7236\n",
      "Epoch 3/25\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 0.9529 - acc: 0.7175 - val_loss: 0.7746 - val_acc: 0.7668\n",
      "Epoch 4/25\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 0.7263 - acc: 0.7734 - val_loss: 0.6653 - val_acc: 0.7981\n",
      "Epoch 5/25\n",
      "6656/6656 [==============================] - 2s 268us/step - loss: 0.5922 - acc: 0.8160 - val_loss: 0.5991 - val_acc: 0.8209\n",
      "Epoch 6/25\n",
      "6656/6656 [==============================] - 2s 272us/step - loss: 0.4979 - acc: 0.8448 - val_loss: 0.5589 - val_acc: 0.8269\n",
      "Epoch 7/25\n",
      "6656/6656 [==============================] - 2s 270us/step - loss: 0.4390 - acc: 0.8601 - val_loss: 0.5546 - val_acc: 0.8317\n",
      "Epoch 8/25\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 0.3757 - acc: 0.8830 - val_loss: 0.5574 - val_acc: 0.8209\n",
      "Epoch 9/25\n",
      "6656/6656 [==============================] - 2s 271us/step - loss: 0.3262 - acc: 0.8980 - val_loss: 0.5396 - val_acc: 0.8293\n",
      "Epoch 10/25\n",
      "6656/6656 [==============================] - 2s 270us/step - loss: 0.3106 - acc: 0.8989 - val_loss: 0.5352 - val_acc: 0.8317\n",
      "Epoch 11/25\n",
      "6656/6656 [==============================] - 2s 271us/step - loss: 0.2781 - acc: 0.9112 - val_loss: 0.5459 - val_acc: 0.8233\n",
      "Epoch 12/25\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 0.2615 - acc: 0.9136 - val_loss: 0.5124 - val_acc: 0.8329\n",
      "Epoch 13/25\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 0.2361 - acc: 0.9220 - val_loss: 0.5373 - val_acc: 0.8221\n",
      "Epoch 14/25\n",
      "6656/6656 [==============================] - 2s 268us/step - loss: 0.2095 - acc: 0.9357 - val_loss: 0.5399 - val_acc: 0.8353\n",
      "Epoch 15/25\n",
      "6656/6656 [==============================] - 2s 270us/step - loss: 0.1977 - acc: 0.9373 - val_loss: 0.5570 - val_acc: 0.8329\n",
      "Epoch 16/25\n",
      "6656/6656 [==============================] - 2s 268us/step - loss: 0.1773 - acc: 0.9437 - val_loss: 0.5075 - val_acc: 0.8425\n",
      "Epoch 17/25\n",
      "6656/6656 [==============================] - 2s 270us/step - loss: 0.1666 - acc: 0.9459 - val_loss: 0.5931 - val_acc: 0.8269\n",
      "Epoch 18/25\n",
      "6656/6656 [==============================] - 2s 267us/step - loss: 0.1597 - acc: 0.9494 - val_loss: 0.5256 - val_acc: 0.8498\n",
      "Epoch 19/25\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 0.1587 - acc: 0.9500 - val_loss: 0.5388 - val_acc: 0.8389\n",
      "Epoch 20/25\n",
      "6656/6656 [==============================] - 2s 272us/step - loss: 0.1475 - acc: 0.9543 - val_loss: 0.5500 - val_acc: 0.8450\n",
      "Epoch 00020: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86548d9ef0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=25,\n",
    "          batch_size=64,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1844 - acc: 0.9357 - val_loss: 0.6105 - val_acc: 0.8229\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1502 - acc: 0.9486 - val_loss: 0.6018 - val_acc: 0.8346\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1632 - acc: 0.9441 - val_loss: 0.5960 - val_acc: 0.8385\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1521 - acc: 0.9458 - val_loss: 0.5984 - val_acc: 0.8320\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1477 - acc: 0.9510 - val_loss: 0.5976 - val_acc: 0.8333\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1513 - acc: 0.9497 - val_loss: 0.5967 - val_acc: 0.8372\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1532 - acc: 0.9504 - val_loss: 0.5994 - val_acc: 0.8411\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86a08c22e8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "model.fit_generator(train_gen_fex,\n",
    "          steps_per_epoch= (6656// 256),\n",
    "          epochs=25,\n",
    "          validation_data=valid_gen_fex,\n",
    "          validation_steps= (832 // 256),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dog-project]",
   "language": "python",
   "name": "conda-env-dog-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
